#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –æ—Ç–∑—ã–≤–∞–º
"""

import os
import sys
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = "/home/analityk/–î–æ–∫—É–º–µ–Ω—Ç—ã/projects/parser_project"
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, "src"))

from src.auto_reviews_parser.parsers.drom import DromParser
from src.auto_reviews_parser.database.repositories.review_repository import (
    ReviewRepository,
)
from src.auto_reviews_parser.database.repositories.comment_repository import (
    CommentRepository,
)
from src.auto_reviews_parser.database.base import Database
from src.auto_reviews_parser.models.comment import Comment


def test_comments_parsing():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"""

    print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –æ—Ç–∑—ã–≤–∞–º...")
    print("=" * 60)

    # –¢–µ—Å—Ç–æ–≤—ã–µ URL –æ—Ç–∑—ã–≤–æ–≤ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
    test_urls = [
        "https://www.drom.ru/reviews/toyota/camry/1440434/",  # –ú–∏—Ö–∞–∏–ª
        "https://www.drom.ru/reviews/toyota/camry/1344577/",  # –î—Ä—É–≥–æ–π –æ—Ç–∑—ã–≤
    ]

    parser = DromParser(gentle_mode=True)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    db = Database("auto_reviews.db")
    review_repo = ReviewRepository(db)
    comment_repo = CommentRepository(db)

    for url in test_urls:
        print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Ç–∑—ã–≤: {url}")
        print("-" * 50)

        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ –æ—Ç–∑—ã–≤ –≤ –±–∞–∑–µ
            reviews = parser.parse_single_review(url)
            if not reviews:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–∑—ã–≤")
                continue

            review = reviews[0]
            print(f"‚úÖ –û—Ç–∑—ã–≤ —Å–ø–∞—Ä—Å–µ–Ω: {review.author}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–∑—ã–≤ –≤ –±–∞–∑—É (–µ—Å–ª–∏ –µ—â–µ –Ω–µ—Ç)
            try:
                review_repo.save(review)
                print("üíæ –û—Ç–∑—ã–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É")
            except Exception as e:
                if "UNIQUE constraint failed" in str(e):
                    print("‚ö†Ô∏è  –û—Ç–∑—ã–≤ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–∑—ã–≤–∞: {e}")
                    continue

            # –ü–∞—Ä—Å–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            print("üìù –ü–∞—Ä—Å–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏...")
            comments_data = parser.parse_comments(url)

            if not comments_data:
                print("‚ùå –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                continue

            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(comments_data)} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")

            # –ü–æ–ª—É—á–∞–µ–º ID –æ—Ç–∑—ã–≤–∞ –∏–∑ –±–∞–∑—ã
            # –ü–æ–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
            review_id = 1  # –≠—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∞—Ç—å –∏–∑ –±–∞–∑—ã –ø–æ URL

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç—ã Comment –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            saved_count = 0
            for comment_data in comments_data:
                if not comment_data.get("content") or not comment_data.get("author"):
                    continue

                comment = Comment(
                    review_id=review_id,
                    author=comment_data["author"],
                    content=comment_data["content"],
                    likes_count=comment_data.get("likes_count", 0),
                    source_url=url,
                    parsed_at=datetime.now(),
                )

                try:
                    comment_repo.save(comment)
                    saved_count += 1
                    print(f"  üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {comment.author[:20]}...")
                except Exception as e:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è: {e}")

            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {saved_count}/{len(comments_data)}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            print(f"\nüìÑ –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:")
            for i, comment_data in enumerate(comments_data[:3], 1):
                if comment_data.get("content"):
                    print(
                        f"   {i}. {comment_data.get('author', '–ê–Ω–æ–Ω–∏–º')}: {comment_data['content'][:100]}..."
                    )

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–∑—ã–≤–∞: {e}")
            import traceback

            traceback.print_exc()

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print("=" * 60)

    try:
        comment_stats = comment_repo.stats()
        print(f"üí¨ –í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ –±–∞–∑–µ: {comment_stats['total_comments']}")
        print(f"üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤: {comment_stats['unique_authors']}")
        print(
            f"üìè –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è: {comment_stats['avg_comment_length']} —Å–∏–º–≤–æ–ª–æ–≤"
        )

        if comment_stats["top_authors"]:
            print(f"üèÜ –¢–æ–ø –∞–≤—Ç–æ—Ä–æ–≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:")
            for author, count in list(comment_stats["top_authors"].items())[:5]:
                print(f"   {author}: {count} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")


if __name__ == "__main__":
    test_comments_parsing()
