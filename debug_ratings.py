#!/usr/bin/env python3
"""
–û—Ç–ª–∞–¥–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ü–µ–Ω–æ–∫ - —Å–º–æ—Ç—Ä–∏–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
"""
import sys
import os
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∫–æ–¥—É
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "src"))

from auto_reviews_parser.parsers.drom import DromParser


def debug_ratings_extraction():
    print("üîß –û—Ç–ª–∞–¥–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ü–µ–Ω–æ–∫...")

    parser = DromParser()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º URL —Å –æ—Ü–µ–Ω–∫–∞–º–∏
    test_url = "https://www.drom.ru/reviews/toyota/camry/1428758/"

    with sync_playwright() as p:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω
        if os.path.exists(parser.chrome_path):
            browser = p.chromium.launch(
                executable_path=parser.chrome_path, headless=True
            )
        else:
            browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        try:
            parser._go_to_page(page, test_url)
            html_content = page.content()
            browser.close()

            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(html_content, "html.parser")

            print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {test_url}")

            # 1. –ò—â–µ–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã
            print(f"\nüìä –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ:")
            tables = soup.find_all("table")
            for i, table in enumerate(tables):
                print(f"\n  –¢–∞–±–ª–∏—Ü–∞ #{i+1}:")
                print(f"    –ö–ª–∞—Å—Å—ã: {table.get('class', '–Ω–µ—Ç')}")

                rows = table.find_all("tr")
                for j, row in enumerate(rows[:5]):  # –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫
                    cells = row.find_all(["td", "th"])
                    if cells:
                        cell_texts = [cell.text.strip() for cell in cells]
                        print(f"    –°—Ç—Ä–æ–∫–∞ {j+1}: {cell_texts}")

            # 2. –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ drom-table
            print(f"\nüéØ –¢–∞–±–ª–∏—Ü—ã drom-table:")
            drom_tables = soup.find_all("table", class_="drom-table")
            for i, table in enumerate(drom_tables):
                print(f"\n  drom-table #{i+1}:")
                rows = table.find_all("tr")
                for row in rows:
                    cells = row.find_all("td")
                    if len(cells) == 2:
                        key = cells[0].text.strip().rstrip(":")
                        value = cells[1].text.strip()
                        print(f"    {key}: {value}")

            # 3. –ò—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É "–í–Ω–µ—à–Ω–∏–π –≤–∏–¥", "–°–∞–ª–æ–Ω" –∏ —Ç.–¥.
            print(f"\nüîç –ü–æ–∏—Å–∫ –æ—Ü–µ–Ω–æ—á–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤:")
            rating_terms = ["–í–Ω–µ—à–Ω–∏–π –≤–∏–¥", "–°–∞–ª–æ–Ω", "–î–≤–∏–≥–∞—Ç–µ–ª—å", "–•–æ–¥–æ–≤—ã–µ –∫–∞—á–µ—Å—Ç–≤–∞"]

            for term in rating_terms:
                elements = soup.find_all(text=lambda text: text and term in text)
                for elem in elements[:2]:  # –ø–µ—Ä–≤—ã–µ 2 –≤—Ö–æ–∂–¥–µ–Ω–∏—è
                    parent = elem.parent
                    if parent:
                        # –ò—â–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —á–∏—Å–ª–∞–º–∏
                        siblings = parent.find_next_siblings()
                        for sibling in siblings[:3]:
                            text = sibling.text.strip()
                            if text and text.isdigit():
                                print(f"    {term}: –Ω–∞–π–¥–µ–Ω–∞ –æ—Ü–µ–Ω–∫–∞ {text}")
                                break

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π —ç–ª–µ–º–µ–Ω—Ç –ø–æ—Å–ª–µ —Ä–æ–¥–∏—Ç–µ–ª—è
                        next_elem = parent.find_next()
                        if next_elem:
                            next_text = next_elem.text.strip()
                            if next_text and (next_text.isdigit() or "/" in next_text):
                                print(f"    {term}: –≤ —Å–ª–µ–¥—É—é—â–µ–º —ç–ª–µ–º–µ–Ω—Ç–µ {next_text}")

            # 4. –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å —á–∏—Å–ª–∞–º–∏ –æ—Ç 1 –¥–æ 10 (–≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏)
            print(f"\nüî¢ –ü–æ–∏—Å–∫ —á–∏—Å–ª–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫:")
            for i in range(1, 11):
                number_elements = soup.find_all(text=str(i))
                rating_context_count = 0
                for elem in number_elements:
                    parent_text = ""
                    if elem.parent:
                        parent_text = elem.parent.text.lower()

                    # –ò—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ü–µ–Ω–æ–∫
                    if any(term.lower() in parent_text for term in rating_terms):
                        rating_context_count += 1
                        if rating_context_count <= 2:  # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2
                            print(f"    –û—Ü–µ–Ω–∫–∞ {i}: –∫–æ–Ω—Ç–µ–∫—Å—Ç '{parent_text[:100]}'")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            browser.close()


if __name__ == "__main__":
    debug_ratings_extraction()
