#!/usr/bin/env python3
"""
üöó –ü–ê–†–°–ï–† –û–¢–ó–´–í–û–í DROM.RU - –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
============================================

–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤ —Å —Å–∞–π—Ç–∞ drom.ru —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
- –î–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ (–ø–æ–¥—Ä–æ–±–Ω—ã–µ –æ–±–∑–æ—Ä—ã)
- –ö–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ (–∫—Ä–∞—Ç–∫–∏–µ –º–Ω–µ–Ω–∏—è)
- –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- –ö–∞—Ç–∞–ª–æ–≥–∏–∑–∞—Ü–∏–∏ –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2024
"""

import requests
import json
import time
import logging
import re
from typing import Dict, List, Optional, Tuple
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from database_schema import DatabaseManager


class DromReviewsParser:
    """–ü–∞—Ä—Å–µ—Ä –æ—Ç–∑—ã–≤–æ–≤ —Å drom.ru —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–≤—É—Ö —Ç–∏–ø–æ–≤ –æ—Ç–∑—ã–≤–æ–≤"""

    def __init__(self, delay: float = 1.0):
        self.base_url = "https://www.drom.ru"
        self.delay = delay
        self.session = requests.Session()
        self.db_manager = DatabaseManager()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.logger = logging.getLogger(__name__)

        # Headers –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/91.0.4472.124 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
            }
        )

    def get_page(self, url: str) -> Optional[BeautifulSoup]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            self.logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")

            response = self.session.get(url, timeout=10)
            response.raise_for_status()

            time.sleep(self.delay)

            soup = BeautifulSoup(response.content, "html.parser")
            return soup

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return None

    def parse_model_page(self, brand_slug: str, model_slug: str) -> Dict[str, int]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–∑—ã–≤–æ–≤"""
        url = f"{self.base_url}/reviews/{brand_slug}/{model_slug}/"
        soup = self.get_page(url)

        if not soup:
            return {"long": 0, "short": 0}

        try:
            # –ü–æ–∏—Å–∫ –±–ª–æ–∫–∞ —Å —Ç–∞–±–∞–º–∏ –æ—Ç–∑—ã–≤–æ–≤
            tabs_block = soup.find("div", {"class": "_65ykvx0"})

            if not tabs_block:
                self.logger.warning(
                    f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω –±–ª–æ–∫ —Ç–∞–±–æ–≤ –¥–ª—è {brand_slug}/{model_slug}"
                )
                return {"long": 0, "short": 0}

            long_count = 0
            short_count = 0

            # –ü–∞—Ä—Å–∏–Ω–≥ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤
            long_tab = tabs_block.find(
                "a", {"data-ftid": "reviews_tab_button_long_reviews"}
            )
            if long_tab:
                long_text = long_tab.get_text()
                long_match = re.search(r"(\d+)\s*–æ—Ç–∑—ã–≤", long_text)
                if long_match:
                    long_count = int(long_match.group(1))

            # –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤
            short_tab = tabs_block.find(
                "a", {"data-ftid": "reviews_tab_button_short_reviews"}
            )
            if short_tab:
                short_text = short_tab.get_text()
                short_match = re.search(r"(\d+(?:\s+\d+)*)\s*–∫–æ—Ä–æ—Ç–æ–∫", short_text)
                if short_match:
                    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏–∑ —á–∏—Å–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä "2 525" -> "2525")
                    short_count_str = short_match.group(1).replace(" ", "")
                    short_count = int(short_count_str)

            self.logger.info(
                f"üìä {brand_slug}/{model_slug}: "
                f"–¥–ª–∏–Ω–Ω—ã—Ö {long_count}, –∫–æ—Ä–æ—Ç–∫–∏—Ö {short_count}"
            )

            return {"long": long_count, "short": short_count}

        except Exception as e:
            self.logger.error(
                f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–æ–¥–µ–ª–∏ {brand_slug}/{model_slug}: {e}"
            )
            return {"long": 0, "short": 0}

    def parse_long_reviews(
        self, brand_slug: str, model_slug: str, limit: int = None
    ) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –º–æ–¥–µ–ª–∏"""
        url = f"{self.base_url}/reviews/{brand_slug}/{model_slug}/"

        reviews = []
        page = 1

        while True:
            page_url = f"{url}?p={page}" if page > 1 else url
            soup = self.get_page(page_url)

            if not soup:
                break

            # –ü–æ–∏—Å–∫ –±–ª–æ–∫–æ–≤ –æ—Ç–∑—ã–≤–æ–≤
            review_blocks = soup.find_all("article", {"data-ftid": "review-item"})

            if not review_blocks:
                self.logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –æ—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                break

            for block in review_blocks:
                try:
                    review_data = self.extract_long_review(
                        block, brand_slug, model_slug
                    )
                    if review_data:
                        reviews.append(review_data)

                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞
                        if limit and len(reviews) >= limit:
                            return reviews

                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–∑—ã–≤–∞: {e}")
                    continue

            self.logger.info(
                f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ {len(review_blocks)} –æ—Ç–∑—ã–≤–æ–≤"
            )
            page += 1

            # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
            if page > 100:
                break

        return reviews

    def extract_long_review(
        self, block: BeautifulSoup, brand_slug: str, model_slug: str
    ) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–ª–æ–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞"""
        try:
            # ID –æ—Ç–∑—ã–≤–∞ –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–∞
            review_id = block.get("id")
            if not review_id:
                return None

            # URL –æ—Ç–∑—ã–≤–∞
            url_link = block.find("a", class_="css-1ycyg4y")
            review_url = None
            if url_link:
                review_url = urljoin(self.base_url, url_link.get("href", ""))

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title_elem = block.find("h3", class_="css-1eac5kj")
            title = title_elem.get_text(strip=True) if title_elem else None

            # –ê–≤—Ç–æ—Ä –∏ –¥–∞—Ç–∞
            author_elem = block.find("span", class_="css-1u4ddp")
            author = author_elem.get_text(strip=True) if author_elem else None

            # –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            date_elem = block.find("time")
            publish_date = None
            if date_elem:
                publish_date = date_elem.get("datetime") or date_elem.get_text(
                    strip=True
                )

            # –†–µ–π—Ç–∏–Ω–≥
            rating_elem = block.find("div", {"data-ftid": "component_rating"})
            rating = None
            if rating_elem:
                rating_text = rating_elem.get_text()
                rating_match = re.search(r"(\d+(?:\.\d+)?)", rating_text)
                if rating_match:
                    rating = float(rating_match.group(1))

            # –ö–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–∑—ã–≤–∞ (–ø–ª—é—Å—ã, –º–∏–Ω—É—Å—ã, –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è)
            content_parts = []

            # –ü–ª—é—Å—ã
            pros_elem = block.find("div", {"data-ftid": "review-content__positive"})
            pros = pros_elem.get_text(strip=True) if pros_elem else None
            if pros:
                content_parts.append(f"–ü–ª—é—Å—ã: {pros}")

            # –ú–∏–Ω—É—Å—ã
            cons_elem = block.find("div", {"data-ftid": "review-content__negative"})
            cons = cons_elem.get_text(strip=True) if cons_elem else None
            if cons:
                content_parts.append(f"–ú–∏–Ω—É—Å—ã: {cons}")

            # –û–±—â–∏–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è
            impression_elem = block.find(
                "div", {"data-ftid": "review-content__general"}
            )
            general_impression = (
                impression_elem.get_text(strip=True) if impression_elem else None
            )
            if general_impression:
                content_parts.append(f"–û–±—â–∏–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è: {general_impression}")

            content = "\n\n".join(content_parts) if content_parts else None

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ–º–æ–±–∏–ª–µ
            car_info = self.extract_car_info(block)

            return {
                "review_id": review_id,
                "review_type": "long",
                "url": review_url,
                "title": title,
                "content": content,
                "author": author,
                "publish_date": publish_date,
                "rating": rating,
                "pros": pros,
                "cons": cons,
                "general_impression": general_impression,
                **car_info,
            }

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞: {e}")
            return None

    def parse_short_reviews(
        self, brand_slug: str, model_slug: str, limit: int = None
    ) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –º–æ–¥–µ–ª–∏"""
        url = f"{self.base_url}/reviews/{brand_slug}/{model_slug}/5kopeek/"

        reviews = []
        page = 1

        while True:
            page_url = f"{url}?p={page}" if page > 1 else url
            soup = self.get_page(page_url)

            if not soup:
                break

            # –ü–æ–∏—Å–∫ –±–ª–æ–∫–æ–≤ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤
            review_blocks = soup.find_all("div", {"data-ftid": "short-review-item"})

            if not review_blocks:
                self.logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                break

            for block in review_blocks:
                try:
                    review_data = self.extract_short_review(
                        block, brand_slug, model_slug
                    )
                    if review_data:
                        reviews.append(review_data)

                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞
                        if limit and len(reviews) >= limit:
                            return reviews

                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ—Ç–∑—ã–≤–∞: {e}")
                    continue

            self.logger.info(
                f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ {len(review_blocks)} –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤"
            )
            page += 1

            # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
            if page > 50:
                break

        return reviews

    def extract_short_review(
        self, block: BeautifulSoup, brand_slug: str, model_slug: str
    ) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–ª–æ–∫–∞ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ—Ç–∑—ã–≤–∞"""
        try:
            # ID –æ—Ç–∑—ã–≤–∞ –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–∞
            review_id = block.get("id")
            if not review_id:
                return None

            # –ê–≤—Ç–æ—Ä (–Ω–æ–º–µ—Ä)
            author_elem = block.find("span", class_="css-1u4ddp")
            author = author_elem.get_text(strip=True) if author_elem else None

            # –ì–æ—Ä–æ–¥
            city_elem = block.find("span", {"data-ftid": "short-review-city"})
            city = city_elem.get_text(strip=True) if city_elem else None

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ–º–æ–±–∏–ª–µ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            title_elem = block.find("div", {"data-ftid": "short-review-item__title"})
            car_info = {}

            if title_elem:
                title_text = title_elem.get_text()

                # –ì–æ–¥
                year_elem = title_elem.find(
                    "span", {"data-ftid": "short-review-item__year"}
                )
                if year_elem:
                    car_info["car_year"] = int(year_elem.get_text())

                # –û–±—ä–µ–º –¥–≤–∏–≥–∞—Ç–µ–ª—è
                volume_elem = title_elem.find(
                    "span", {"data-ftid": "short-review-item__volume"}
                )
                if volume_elem:
                    car_info["car_volume"] = float(volume_elem.get_text())

                # –ü–∞—Ä—Å–∏–Ω–≥ –æ—Å—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞
                # –§–æ—Ä–º–∞—Ç: "2001 –≥–æ–¥, 1.5 –ª, –±–µ–Ω–∑–∏–Ω, –∞–≤—Ç–æ–º–∞—Ç, –ø–µ—Ä–µ–¥–Ω–∏–π"
                parts = title_text.split(", ")
                if len(parts) >= 5:
                    car_info["car_fuel_type"] = parts[2].strip()
                    car_info["car_transmission"] = parts[3].strip()
                    car_info["car_drive"] = parts[4].strip()

            # –ü–ª—é—Å—ã
            pros_elem = block.find(
                "div", {"data-ftid": "short-review-content__positive"}
            )
            pros = pros_elem.get_text(strip=True) if pros_elem else None

            # –ú–∏–Ω—É—Å—ã
            cons_elem = block.find(
                "div", {"data-ftid": "short-review-content__negative"}
            )
            cons = cons_elem.get_text(strip=True) if cons_elem else None

            # –ü–æ–ª–æ–º–∫–∏
            breakages_elem = block.find(
                "div", {"data-ftid": "short-review-content__breakages"}
            )
            breakages = breakages_elem.get_text(strip=True) if breakages_elem else None

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            content_parts = []
            if pros:
                content_parts.append(f"–ü–ª—é—Å—ã: {pros}")
            if cons:
                content_parts.append(f"–ú–∏–Ω—É—Å—ã: {cons}")
            if breakages:
                content_parts.append(f"–ü–æ–ª–æ–º–∫–∏: {breakages}")

            content = "\n\n".join(content_parts) if content_parts else None

            # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
            photos = []
            photo_blocks = block.find_all("img", class_="css-1e2elm8")
            for img in photo_blocks:
                src = img.get("src") or img.get("srcset", "").split(" ")[0]
                if src:
                    photos.append(src)

            photos_json = json.dumps(photos) if photos else None

            return {
                "review_id": f"short_{review_id}",
                "review_type": "short",
                "url": f"{self.base_url}/reviews/{brand_slug}/{model_slug}/5kopeek/#{review_id}",
                "title": f"–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–∑—ã–≤ {car_info.get('car_year', '')} {car_info.get('car_volume', '')}–ª",
                "content": content,
                "author": author,
                "city": city,
                "pros": pros,
                "cons": cons,
                "breakages": breakages,
                "photos": photos_json,
                **car_info,
            }

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ—Ç–∑—ã–≤–∞: {e}")
            return None

    def extract_car_info(self, block: BeautifulSoup) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–≤—Ç–æ–º–æ–±–∏–ª–µ –∏–∑ –±–ª–æ–∫–∞ –æ—Ç–∑—ã–≤–∞"""
        car_info = {}

        try:
            # –ü–æ–∏—Å–∫ –±–ª–æ–∫–∞ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
            specs_block = block.find("div", class_="css-1ymyv8x")

            if specs_block:
                specs_text = specs_block.get_text()

                # –ü–∞—Ä—Å–∏–Ω–≥ –≥–æ–¥–∞
                year_match = re.search(r"(\d{4})\s*–≥", specs_text)
                if year_match:
                    car_info["car_year"] = int(year_match.group(1))

                # –ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä–µ–º–∞ –¥–≤–∏–≥–∞—Ç–µ–ª—è
                volume_match = re.search(r"(\d+(?:\.\d+)?)\s*–ª", specs_text)
                if volume_match:
                    car_info["car_volume"] = float(volume_match.group(1))

                # –î—Ä—É–≥–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ –º–µ—Ä–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–≤—Ç–æ–º–æ–±–∏–ª–µ: {e}")

        return car_info

    def save_reviews(
        self, reviews: List[Dict], brand_slug: str, model_slug: str
    ) -> int:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        saved_count = 0

        for review in reviews:
            try:
                result = self.db_manager.add_review(
                    brand_slug=brand_slug, model_slug=model_slug, **review
                )

                if result:
                    saved_count += 1

            except Exception as e:
                self.logger.error(
                    f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–∑—ã–≤–∞ {review.get('review_id', 'unknown')}: {e}"
                )

        return saved_count

    def parse_model_reviews(
        self,
        brand_slug: str,
        model_slug: str,
        long_limit: int = None,
        short_limit: int = None,
    ) -> Dict[str, int]:
        """–ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ –º–æ–¥–µ–ª–∏ (–¥–ª–∏–Ω–Ω—ã—Ö –∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö)"""
        results = {"long": 0, "short": 0}

        self.logger.info(f"üöó –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ {brand_slug}/{model_slug}")

        # –ü–∞—Ä—Å–∏–Ω–≥ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤
        if long_limit is None or long_limit > 0:
            self.logger.info("üìù –ü–∞—Ä—Å–∏–Ω–≥ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤...")
            long_reviews = self.parse_long_reviews(brand_slug, model_slug, long_limit)

            if long_reviews:
                saved_long = self.save_reviews(long_reviews, brand_slug, model_slug)
                results["long"] = saved_long
                self.logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_long} –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤")

        # –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤
        if short_limit is None or short_limit > 0:
            self.logger.info("üî∏ –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤...")
            short_reviews = self.parse_short_reviews(
                brand_slug, model_slug, short_limit
            )

            if short_reviews:
                saved_short = self.save_reviews(short_reviews, brand_slug, model_slug)
                results["short"] = saved_short
                self.logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_short} –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤")

        total_saved = results["long"] + results["short"]
        self.logger.info(f"üéâ –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {total_saved}")

        return results


def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞"""
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )

    parser = DromReviewsParser(delay=1.5)

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ Toyota 4Runner
    brand_slug = "toyota"
    model_slug = "4runner"

    print(f"üöó –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–ê–†–°–ï–†–ê –û–¢–ó–´–í–û–í")
    print(f"–ú–æ–¥–µ–ª—å: {brand_slug}/{model_slug}")
    print("=" * 50)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–∑—ã–≤–æ–≤
    counts = parser.parse_model_page(brand_slug, model_slug)
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤:")
    print(f"- –î–ª–∏–Ω–Ω—ã—Ö: {counts['long']}")
    print(f"- –ö–æ—Ä–æ—Ç–∫–∏—Ö: {counts['short']}")

    # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ–±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
    results = parser.parse_model_reviews(
        brand_slug, model_slug, long_limit=3, short_limit=5
    )

    print(f"\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–ê–†–°–ò–ù–ì–ê:")
    print(f"- –î–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {results['long']}")
    print(f"- –ö–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {results['short']}")


if __name__ == "__main__":
    main()
