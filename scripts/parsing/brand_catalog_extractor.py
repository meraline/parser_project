#!/usr/bin/env python3
"""
üîç –≠–ö–°–¢–†–ê–ö–¢–û–† –ö–ê–¢–ê–õ–û–ì–ê –ë–†–ï–ù–î–û–í DROM.RU

–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π —Å —Å–∞–π—Ç–∞ drom.ru
–¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø–∞—Ä—Å–µ—Ä–µ –æ—Ç–∑—ã–≤–æ–≤.

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ URL: https://www.drom.ru/reviews/toyota/4runner/1425079/
- –ü—Ä–æ—Ç–æ–∫–æ–ª: https://
- –î–æ–º–µ–Ω: www.drom.ru
- –†–∞–∑–¥–µ–ª: /reviews/
- –ë—Ä–µ–Ω–¥: /toyota/
- –ú–æ–¥–µ–ª—å: /4runner/
- ID –æ—Ç–∑—ã–≤–∞: /1425079/
"""

import json
import logging
import time
from pathlib import Path
from typing import Dict, List, Set, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

import requests
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright


@dataclass
class BrandInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±—Ä–µ–Ω–¥–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π"""

    name: str
    slug: str
    url: str
    review_count: int
    models: List[str] = None

    def __post_init__(self):
        if self.models is None:
            self.models = []


@dataclass
class CatalogData:
    """–ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∞"""

    extraction_date: str
    total_brands: int
    brands: Dict[str, BrandInfo]

    @classmethod
    def from_dict(cls, data: dict):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        brands = {}
        for slug, brand_data in data.get("brands", {}).items():
            brands[slug] = BrandInfo(**brand_data)

        return cls(
            extraction_date=data.get("extraction_date", ""),
            total_brands=data.get("total_brands", 0),
            brands=brands,
        )

    def to_dict(self) -> dict:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON"""
        return {
            "extraction_date": self.extraction_date,
            "total_brands": self.total_brands,
            "brands": {slug: asdict(brand) for slug, brand in self.brands.items()},
        }


class BrandCatalogExtractor:
    """–≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤ —Å Drom.ru"""

    def __init__(
        self,
        catalog_file: str = "data/brand_catalog.json",
        browser_path: str = "/home/analityk/–î–æ–∫—É–º–µ–Ω—Ç—ã/projects/parser_project/chrome-linux/chrome",
    ):
        self.catalog_file = Path(catalog_file)
        self.browser_path = browser_path
        self.base_url = "https://www.drom.ru/reviews/"

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
        self.catalog_file.parent.mkdir(parents=True, exist_ok=True)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler("logs/brand_extractor.log"),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger(__name__)

    def extract_brands_from_html(self, html_content: str) -> Dict[str, BrandInfo]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–æ–≤ –∏–∑ HTML-–±–ª–æ–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞"""
        soup = BeautifulSoup(html_content, "html.parser")
        brands = {}

        # –ò—â–µ–º –±–ª–æ–∫ —Å –±—Ä–µ–Ω–¥–∞–º–∏
        brands_container = soup.find("div", {"data-ftid": "component_cars-list"})
        if not brands_container:
            self.logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –±—Ä–µ–Ω–¥–∞–º–∏")
            return brands

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –±—Ä–µ–Ω–¥–æ–≤
        brand_items = brands_container.find_all("div", class_="frg44i0")

        for item in brand_items:
            try:
                # –ù–∞–∑–≤–∞–Ω–∏–µ –±—Ä–µ–Ω–¥–∞
                name_elem = item.find(
                    "span", {"data-ftid": "component_cars-list-item_name"}
                )
                if not name_elem:
                    continue

                name = name_elem.get_text(strip=True)

                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
                count_elem = item.find(
                    "span", {"data-ftid": "component_cars-list-item_counter"}
                )
                review_count = 0
                if count_elem:
                    count_text = count_elem.get_text(strip=True)
                    try:
                        review_count = int(count_text.replace(" ", "").replace(",", ""))
                    except (ValueError, AttributeError):
                        review_count = 0

                # –°—Å—ã–ª–∫–∞ –Ω–∞ –±—Ä–µ–Ω–¥
                link_elem = item.find(
                    "a", {"data-ftid": "component_cars-list-item_hidden-link"}
                )
                if not link_elem:
                    continue

                url = link_elem.get("href", "")
                if not url:
                    continue

                # –ò–∑–≤–ª–µ–∫–∞–µ–º slug –∏–∑ URL (–Ω–∞–ø—Ä–∏–º–µ—Ä, /reviews/toyota/ -> toyota)
                slug = url.strip("/").split("/")[-1]

                brands[slug] = BrandInfo(
                    name=name, slug=slug, url=url, review_count=review_count
                )

                self.logger.info(
                    f"–ò–∑–≤–ª–µ—á–µ–Ω –±—Ä–µ–Ω–¥: {name} ({slug}) - {review_count} –æ—Ç–∑—ã–≤–æ–≤"
                )

            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –±—Ä–µ–Ω–¥–∞: {e}")
                continue

        return brands

    def extract_models_for_brand(self, brand_slug: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞"""
        models = []

        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(
                    executable_path=self.browser_path,
                    headless=True,
                    args=["--no-sandbox", "--disable-dev-shm-usage"],
                )

                page = browser.new_page()

                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –±—Ä–µ–Ω–¥–∞
                brand_url = f"{self.base_url}{brand_slug}/"
                self.logger.info(f"–ò–∑–≤–ª–µ–∫–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è {brand_slug}: {brand_url}")

                page.goto(brand_url, wait_until="networkidle")
                time.sleep(2)

                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–æ–¥–µ–ª–∏ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è)
                model_links = page.query_selector_all(
                    'a[href*="/reviews/' + brand_slug + '/"]'
                )

                for link in model_links:
                    href = link.get_attribute("href")
                    if href and href.count("/") >= 4:  # /reviews/brand/model/
                        model_slug = href.strip("/").split("/")[-1]
                        if model_slug not in models and model_slug != brand_slug:
                            models.append(model_slug)

                browser.close()

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è {brand_slug}: {e}")

        self.logger.info(
            f"–ù–∞–π–¥–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –¥–ª—è {brand_slug}: {models[:5]}..."
        )
        return models

    def extract_full_catalog(self) -> CatalogData:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤"""
        self.logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤...")

        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(
                    executable_path=self.browser_path,
                    headless=True,
                    args=["--no-sandbox", "--disable-dev-shm-usage"],
                )

                page = browser.new_page()
                page.goto(self.base_url, wait_until="networkidle")
                time.sleep(3)

                # –ü–æ–ª—É—á–∞–µ–º HTML —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                html_content = page.content()
                browser.close()

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –±—Ä–µ–Ω–¥—ã
                brands = self.extract_brands_from_html(html_content)

                # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥
                catalog = CatalogData(
                    extraction_date=datetime.now().isoformat(),
                    total_brands=len(brands),
                    brands=brands,
                )

                self.logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(brands)} –±—Ä–µ–Ω–¥–æ–≤")
                return catalog

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
            return CatalogData(
                extraction_date=datetime.now().isoformat(), total_brands=0, brands={}
            )

    def extract_models_for_all_brands(
        self, catalog: CatalogData, max_brands: Optional[int] = None
    ) -> CatalogData:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—Å–µ—Ö –±—Ä–µ–Ω–¥–æ–≤"""
        self.logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—Å–µ—Ö –±—Ä–µ–Ω–¥–æ–≤...")

        brand_list = list(catalog.brands.items())
        if max_brands:
            brand_list = brand_list[:max_brands]

        for i, (slug, brand) in enumerate(brand_list, 1):
            self.logger.info(
                f"[{i}/{len(brand_list)}] –ò–∑–≤–ª–µ–∫–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è {brand.name}"
            )

            try:
                models = self.extract_models_for_brand(slug)
                brand.models = models

                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(1)

            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è {slug}: {e}")
                brand.models = []

        return catalog

    def save_catalog(self, catalog: CatalogData):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –≤ JSON —Ñ–∞–π–ª"""
        try:
            with open(self.catalog_file, "w", encoding="utf-8") as f:
                json.dump(catalog.to_dict(), f, ensure_ascii=False, indent=2)

            self.logger.info(f"–ö–∞—Ç–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {self.catalog_file}")

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")

    def load_catalog(self) -> Optional[CatalogData]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        if not self.catalog_file.exists():
            return None

        try:
            with open(self.catalog_file, "r", encoding="utf-8") as f:
                data = json.load(f)

            catalog = CatalogData.from_dict(data)
            self.logger.info(f"–ö–∞—Ç–∞–ª–æ–≥ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {self.catalog_file}")
            return catalog

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
            return None

    def update_catalog(self) -> CatalogData:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞ (–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –±—Ä–µ–Ω–¥–æ–≤)"""
        self.logger.info("–ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–∞—Ç–∞–ª–æ–≥
        old_catalog = self.load_catalog()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—ã–π –∫–∞—Ç–∞–ª–æ–≥
        new_catalog = self.extract_full_catalog()

        if old_catalog is None:
            self.logger.info("–°—Ç–∞—Ä—ã–π –∫–∞—Ç–∞–ª–æ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π")
            return new_catalog

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥–∏
        old_brands = set(old_catalog.brands.keys())
        new_brands = set(new_catalog.brands.keys())

        added_brands = new_brands - old_brands
        removed_brands = old_brands - new_brands

        if added_brands:
            self.logger.info(f"–ù–æ–≤—ã–µ –±—Ä–µ–Ω–¥—ã: {list(added_brands)}")

        if removed_brands:
            self.logger.info(f"–£–¥–∞–ª–µ–Ω–Ω—ã–µ –±—Ä–µ–Ω–¥—ã: {list(removed_brands)}")

        if not added_brands and not removed_brands:
            self.logger.info("–ò–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            return old_catalog

        return new_catalog

    def get_brand_stats(self, catalog: CatalogData) -> dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É"""
        if not catalog.brands:
            return {}

        total_reviews = sum(brand.review_count for brand in catalog.brands.values())
        brands_with_models = sum(1 for brand in catalog.brands.values() if brand.models)
        total_models = sum(len(brand.models) for brand in catalog.brands.values())

        # –¢–æ–ø –±—Ä–µ–Ω–¥–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ—Ç–∑—ã–≤–æ–≤
        top_brands = sorted(
            catalog.brands.values(), key=lambda x: x.review_count, reverse=True
        )[:10]

        return {
            "total_brands": catalog.total_brands,
            "total_reviews": total_reviews,
            "brands_with_models": brands_with_models,
            "total_models": total_models,
            "extraction_date": catalog.extraction_date,
            "top_brands": [
                {
                    "name": brand.name,
                    "slug": brand.slug,
                    "review_count": brand.review_count,
                    "models_count": len(brand.models) if brand.models else 0,
                }
                for brand in top_brands
            ],
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    import argparse

    parser = argparse.ArgumentParser(description="–≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤ Drom.ru")
    parser.add_argument("--extract", action="store_true", help="–ò–∑–≤–ª–µ—á—å –Ω–æ–≤—ã–π –∫–∞—Ç–∞–ª–æ–≥")
    parser.add_argument(
        "--models", action="store_true", help="–ò–∑–≤–ª–µ—á—å –º–æ–¥–µ–ª–∏ –¥–ª—è –±—Ä–µ–Ω–¥–æ–≤"
    )
    parser.add_argument("--update", action="store_true", help="–û–±–Ω–æ–≤–∏—Ç—å –∫–∞—Ç–∞–ª–æ–≥")
    parser.add_argument("--stats", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
    parser.add_argument(
        "--max-brands", type=int, help="–ú–∞–∫—Å–∏–º—É–º –±—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"
    )

    args = parser.parse_args()

    extractor = BrandCatalogExtractor()

    if args.extract:
        print("üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥ –±—Ä–µ–Ω–¥–æ–≤...")
        catalog = extractor.extract_full_catalog()
        extractor.save_catalog(catalog)

        if args.models:
            print("üöó –ò–∑–≤–ª–µ–∫–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –±—Ä–µ–Ω–¥–æ–≤...")
            catalog = extractor.extract_models_for_all_brands(catalog, args.max_brands)
            extractor.save_catalog(catalog)

    elif args.update:
        print("üîÑ –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–∞–ª–æ–≥...")
        catalog = extractor.update_catalog()
        extractor.save_catalog(catalog)

    elif args.stats:
        catalog = extractor.load_catalog()
        if catalog:
            stats = extractor.get_brand_stats(catalog)
            print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–ê–¢–ê–õ–û–ì–ê:")
            print(f"–í—Å–µ–≥–æ –±—Ä–µ–Ω–¥–æ–≤: {stats['total_brands']}")
            print(f"–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {stats['total_reviews']:,}")
            print(f"–ë—Ä–µ–Ω–¥–æ–≤ —Å –º–æ–¥–µ–ª—è–º–∏: {stats['brands_with_models']}")
            print(f"–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {stats['total_models']}")
            print(f"–î–∞—Ç–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {stats['extraction_date']}")

            print("\nüèÜ –¢–û–ü-10 –ë–†–ï–ù–î–û–í –ü–û –û–¢–ó–´–í–ê–ú:")
            for i, brand in enumerate(stats["top_brands"], 1):
                print(
                    f"{i:2d}. {brand['name']:15} - {brand['review_count']:6,} –æ—Ç–∑—ã–≤–æ–≤, {brand['models_count']:3d} –º–æ–¥–µ–ª–µ–π"
                )

    else:
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --extract, --update –∏–ª–∏ --stats")


if __name__ == "__main__":
    main()
