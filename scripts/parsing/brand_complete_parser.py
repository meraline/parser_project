#!/usr/bin/env python3
"""
ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ²ÑĞµÑ… Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ¿Ğ¾ Ğ±Ñ€ĞµĞ½Ğ´Ğ°Ğ¼ (Ğ°Ğ»Ñ„Ğ°Ğ²Ğ¸Ñ‚Ğ½Ğ¾)
- ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ’Ğ¡Ğ• Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‹ Ğ±Ñ€ĞµĞ½Ğ´Ğ°, Ğ·Ğ°Ñ‚ĞµĞ¼ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ±Ñ€ĞµĞ½Ğ´
- ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ Ñ‡ĞµÑ€ĞµĞ· Ğ±Ğ°Ğ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 10 Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²
- 30 Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ°
"""

import time
import sqlite3
import traceback
from typing import Set, List
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ
import sys

sys.path.append(str(Path(__file__).parent.parent.parent))

from src.auto_reviews_parser.parsers.drom import DromParser
from src.auto_reviews_parser.database.base import DatabaseManager
from src.auto_reviews_parser.utils.delay_manager import DelayManager
from src.auto_reviews_parser.models.review import Review


class BrandCompleteParser:
    """ĞŸĞ°Ñ€ÑĞµÑ€ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ¿Ğ¾ Ğ±Ñ€ĞµĞ½Ğ´Ğ°Ğ¼."""

    def __init__(self):
        self.brands = self._get_brands_alphabetical()
        self.parser = DromParser()
        self.db_manager = DatabaseManager("data/databases/brand_complete_test.db")
        self.delay_manager = DelayManager()

        self.stats = {
            "start_time": time.time(),
            "total_parsed": 0,
            "successful_parsed": 0,
            "comments_parsed": 0,
            "current_brand": "",
            "last_save_time": time.time(),
        }

        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ‘Ğ”
        self._init_database()

    def _get_brands_alphabetical(self) -> List[str]:
        """Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ±Ñ€ĞµĞ½Ğ´Ğ¾Ğ² Ğ² Ğ°Ğ»Ñ„Ğ°Ğ²Ğ¸Ñ‚Ğ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ."""
        brands = [
            "audi",
            "bmw",
            "chevrolet",
            "daewoo",
            "ford",
            "honda",
            "hyundai",
            "kia",
            "mazda",
            "mercedes-benz",
            "mitsubishi",
            "nissan",
            "opel",
            "peugeot",
            "renault",
            "skoda",
            "subaru",
            "suzuki",
            "toyota",
            "volkswagen",
            "volvo",
        ]
        return sorted(brands)

    def _init_database(self):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ† Ğ‘Ğ”."""
        with sqlite3.connect(self.db_manager.db_path) as conn:
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS parsed_reviews (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    url TEXT UNIQUE NOT NULL,
                    brand TEXT NOT NULL,
                    model TEXT NOT NULL,
                    year INTEGER,
                    rating REAL,
                    title TEXT,
                    content TEXT,
                    author TEXT,
                    date_published TEXT,
                    date_parsed TEXT DEFAULT CURRENT_TIMESTAMP,
                    comments_count INTEGER DEFAULT 0
                )
            """
            )
            conn.commit()

    def get_existing_urls(self) -> Set[str]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑƒĞ¶Ğµ ÑĞ¿Ğ°Ñ€ÑĞµĞ½Ğ½Ñ‹Ñ… URL Ğ¸Ğ· Ğ‘Ğ”."""
        with sqlite3.connect(self.db_manager.db_path) as conn:
            cursor = conn.execute("SELECT url FROM parsed_reviews")
            return {row[0] for row in cursor.fetchall()}

    def get_all_brand_review_urls(self, brand: str) -> List[str]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ’Ğ¡Ğ•Ğ¥ URL Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ´Ğ»Ñ Ğ±Ñ€ĞµĞ½Ğ´Ğ°."""
        print(f"   ğŸ” ĞŸĞ¾Ğ¸ÑĞº Ğ²ÑĞµÑ… Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ´Ğ»Ñ Ğ±Ñ€ĞµĞ½Ğ´Ğ°: {brand}")

        models = self._get_brand_models(brand)
        all_urls = []

        for model in models[:5]:  # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ°
            try:
                model_urls = self.parser.get_model_review_urls(brand, model)
                all_urls.extend(model_urls)
                print(f"     ğŸ“„ {model}: {len(model_urls)} Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²")
                time.sleep(1)  # ĞŸĞ°ÑƒĞ·Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸
            except Exception as e:
                print(f"     âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ´Ğ»Ñ {model}: {e}")

        print(f"   ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ URL Ğ´Ğ»Ñ {brand}: {len(all_urls)}")
        return all_urls

    def _get_brand_models(self, brand: str) -> List[str]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ¸ÑĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ±Ñ€ĞµĞ½Ğ´Ğ°."""
        models_map = {
            "toyota": ["camry", "corolla", "rav4", "land-cruiser", "prius"],
            "honda": ["civic", "accord", "cr-v", "pilot", "fit"],
            "bmw": ["3-series", "5-series", "x3", "x5", "x1"],
            "audi": ["a4", "a6", "q5", "q7", "a3"],
            "mercedes-benz": ["c-class", "e-class", "glc", "gle", "a-class"],
            "volkswagen": ["golf", "passat", "tiguan", "polo", "jetta"],
            "hyundai": ["elantra", "tucson", "santa-fe", "accent", "sonata"],
            "kia": ["rio", "cerato", "sportage", "sorento", "optima"],
            "mazda": ["3", "6", "cx-5", "cx-9", "2"],
            "nissan": ["qashqai", "x-trail", "juke", "almera", "teana"],
            "ford": ["focus", "fiesta", "kuga", "mondeo", "ecosport"],
            "chevrolet": ["cruze", "captiva", "aveo", "malibu", "tahoe"],
            "skoda": ["octavia", "rapid", "superb", "kodiaq", "fabia"],
            "renault": ["logan", "duster", "megane", "kaptur", "sandero"],
            "opel": ["astra", "corsa", "insignia", "mokka", "zafira"],
            "peugeot": ["308", "3008", "2008", "408", "5008"],
            "mitsubishi": ["outlander", "asx", "lancer", "pajero", "l200"],
            "subaru": ["forester", "outback", "impreza", "xv", "legacy"],
            "suzuki": ["vitara", "swift", "sx4", "jimny", "baleno"],
            "volvo": ["xc60", "xc90", "v60", "s60", "v40"],
            "daewoo": ["nexia", "matiz", "gentra", "lacetti", "espero"],
        }
        return models_map.get(brand, [brand])

    def parse_single_review(self, url: str) -> dict:
        """ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°."""
        try:
            review_data = self.parser.parse_review_page(url)
            if review_data and review_data.get("review"):
                return {
                    "status": "success",
                    "review": review_data["review"],
                    "comments": review_data.get("comments", []),
                    "url": url,
                }
            else:
                return {"status": "error", "error": "ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°", "url": url}
        except Exception as e:
            return {"status": "error", "error": str(e), "url": url}

    def save_batch(self, results_batch: List[dict]):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ‘Ğ”."""
        print(f"   ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ {len(results_batch)} Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ² Ğ‘Ğ”...")

        with sqlite3.connect(self.db_manager.db_path) as conn:
            for result in results_batch:
                if result["status"] == "success":
                    review = result["review"]
                    conn.execute(
                        """
                        INSERT OR IGNORE INTO parsed_reviews 
                        (url, brand, model, year, rating, title, content, 
                         author, date_published, comments_count)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                        (
                            result["url"],
                            review.brand,
                            review.model,
                            review.year,
                            review.rating,
                            review.title,
                            review.content,
                            review.author,
                            review.date_published,
                            len(result.get("comments", [])),
                        ),
                    )
            conn.commit()

        self.stats["last_save_time"] = time.time()
        print(f"   âœ… Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ Ğ² Ğ‘Ğ”")

    def start_parsing(self, target_reviews: int = 30):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° Ğ¿Ğ¾ Ğ±Ñ€ĞµĞ½Ğ´Ğ°Ğ¼."""
        self.stats["start_time"] = time.time()

        print("\nğŸ¯ Ğ¡Ğ¢ĞĞ Ğ¢ ĞŸĞĞ›ĞĞĞ“Ğ ĞŸĞĞ Ğ¡Ğ˜ĞĞ“Ğ ĞŸĞ Ğ‘Ğ Ğ•ĞĞ”ĞĞœ")
        print("=" * 50)
        print(f"ğŸ“Š Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ Ñ†ĞµĞ»ÑŒ: {target_reviews} Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²")
        print("ğŸ·ï¸ Ğ›Ğ¾Ğ³Ğ¸ĞºĞ°: Ğ’Ğ¡Ğ• Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‹ Ğ±Ñ€ĞµĞ½Ğ´Ğ° â†’ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ±Ñ€ĞµĞ½Ğ´")
        print("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 10 Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²")
        print("ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ² Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ°")
        print("=" * 50)

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ URL
        existing_urls = self.get_existing_urls()
        print(f"ğŸ“‹ Ğ£Ğ¶Ğµ Ğ² Ğ‘Ğ”: {len(existing_urls)} URL")

        results_batch = []

        try:
            for brand in self.brands:
                if self.stats["total_parsed"] >= target_reviews:
                    break

                self.stats["current_brand"] = brand
                print(f"\nğŸ·ï¸ ĞŸĞĞ›ĞĞ«Ğ™ ĞŸĞĞ Ğ¡Ğ˜ĞĞ“ Ğ‘Ğ Ğ•ĞĞ”Ğ: {brand.upper()}")

                # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ’Ğ¡Ğ• URL Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ´Ğ»Ñ Ğ±Ñ€ĞµĞ½Ğ´Ğ°
                brand_urls = self.get_all_brand_review_urls(brand)

                # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹
                new_urls = [url for url in brand_urls if url not in existing_urls]

                print(f"   ğŸ“‹ ĞĞ¾Ğ²Ñ‹Ñ… URL: {len(new_urls)}")
                print(f"   âš ï¸ Ğ”ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²: {len(brand_urls) - len(new_urls)}")

                brand_parsed = 0

                for url in new_urls:
                    if self.stats["total_parsed"] >= target_reviews:
                        print(f"   ğŸ¯ Ğ”Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚Ğ° Ñ†ĞµĞ»ÑŒ: {target_reviews}")
                        break

                    if (time.time() - self.stats["last_save_time"]) > 30:
                        print(
                            f"   ğŸ“„ ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ: {self.stats['total_parsed'] + 1}"
                            f"/{target_reviews}"
                        )

                    # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ¾Ñ‚Ğ·Ñ‹Ğ²
                    result = self.parse_single_review(url)

                    if result["status"] == "success":
                        results_batch.append(result)
                        existing_urls.add(url)
                        brand_parsed += 1
                        self.stats["total_parsed"] += 1
                        self.stats["successful_parsed"] += 1
                        self.stats["comments_parsed"] += len(result.get("comments", []))

                        review = result["review"]
                        print(
                            f"   âœ… {review.brand} {review.model} " f"({review.year})"
                        )
                    else:
                        print(f"   âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {result.get('error', '?')[:50]}")

                    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 10 Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²
                    if len(results_batch) >= 10:
                        self.save_batch(results_batch)
                        results_batch = []

                    self.delay_manager.wait()

                print(f"   ğŸ“Š Ğ‘Ñ€ĞµĞ½Ğ´ {brand} Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½: {brand_parsed} Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²")

            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾ÑÑ‚Ğ°Ğ²ÑˆĞ¸ĞµÑÑ
            if results_batch:
                self.save_batch(results_batch)

            print("\nâœ… ĞŸĞĞ›ĞĞ«Ğ™ ĞŸĞĞ Ğ¡Ğ˜ĞĞ“ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•Ğ!")

        except KeyboardInterrupt:
            print("\nâ¹ï¸ ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ğ½ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼")
            if results_batch:
                self.save_batch(results_batch)

        except Exception as e:
            print(f"\nğŸ’¥ ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
            traceback.print_exc()
            if results_batch:
                self.save_batch(results_batch)

        finally:
            self.print_final_stats()

    def print_final_stats(self):
        """ĞŸĞµÑ‡Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸."""
        elapsed = time.time() - self.stats["start_time"]

        print("\n" + "=" * 50)
        print("ğŸ“Š Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞĞ¯ Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ")
        print("=" * 50)
        print(f"â±ï¸ Ğ’Ñ€ĞµĞ¼Ñ: {elapsed:.1f} ÑĞµĞº ({elapsed/60:.1f} Ğ¼Ğ¸Ğ½)")
        print(f"âœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾: {self.stats['successful_parsed']}")
        print(f"ğŸ“ Ğ’ÑĞµĞ³Ğ¾: {self.stats['total_parsed']}")
        print(f"ğŸ’¬ ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²: {self.stats['comments_parsed']}")
        print(f"ğŸ·ï¸ Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ±Ñ€ĞµĞ½Ğ´: {self.stats['current_brand']}")

        if elapsed > 0:
            speed = self.stats["total_parsed"] / elapsed * 3600
            print(f"ğŸ“ˆ Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ: {speed:.0f} Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²/Ñ‡Ğ°Ñ")

        print("ğŸ’¾ Ğ‘Ğ”: data/databases/brand_complete_test.db")
        print("=" * 50)


def main():
    """Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°."""
    print("ğŸš€ ĞŸĞĞ›ĞĞ«Ğ™ ĞŸĞĞ Ğ¡Ğ˜ĞĞ“ ĞĞ¢Ğ—Ğ«Ğ’ĞĞ’ ĞŸĞ Ğ‘Ğ Ğ•ĞĞ”ĞĞœ")
    print("Ğ›Ğ¾Ğ³Ğ¸ĞºĞ°: Ğ’Ğ¡Ğ• Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‹ Ğ±Ñ€ĞµĞ½Ğ´Ğ° â†’ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ±Ñ€ĞµĞ½Ğ´")

    parser = BrandCompleteParser()
    parser.start_parsing(target_reviews=30)


if __name__ == "__main__":
    main()
