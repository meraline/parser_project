#!/usr/bin/env python3
"""
üöÄ –ö–ê–¢–ê–õ–û–ñ–ù–´–ô –ü–ê–†–°–ï–† –û–¢–ó–´–í–û–í DROM.RU

–ü–∞—Ä—Å–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ –±—Ä–µ–Ω–¥–æ–≤
–¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–æ–≤.

–î–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–µ–∂–∏–º–∞:
1. –ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –±—Ä–µ–Ω–¥–æ–≤ –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É
2. –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞ —Å –µ–≥–æ –º–æ–¥–µ–ª—è–º–∏

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–æ—Ç–æ–≤—ã–π –∫–∞—Ç–∞–ª–æ–≥ –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π
- –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–Ω–µ —Å–ª—É—á–∞–π–Ω–∞—è)
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å –Ω–µ–ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
"""

import json
import logging
import time
import sqlite3
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

from playwright.sync_api import sync_playwright

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
import sys

sys.path.append(str(Path(__file__).parent.parent.parent))

from scripts.parsing.normalized_parser import NormalizedDatabaseParser
from scripts.parsing.brand_catalog_extractor import (
    BrandCatalogExtractor,
    CatalogData,
    BrandInfo,
)


@dataclass
class ParseResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞"""

    brand_slug: str
    brand_name: str
    total_models: int
    processed_models: int
    total_reviews: int
    new_reviews: int
    skipped_reviews: int
    error_reviews: int
    duration_seconds: float
    errors: List[str]


class CatalogBasedParser:
    """–ü–∞—Ä—Å–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤"""

    def __init__(
        self,
        catalog_file: str = "data/brand_catalog.json",
        database_path: str = "–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è_–±–¥_v3.db",
        browser_path: str = "/home/analityk/–î–æ–∫—É–º–µ–Ω—Ç—ã/projects/parser_project/chrome-linux/chrome",
    ):

        self.catalog_file = Path(catalog_file)
        self.database_path = database_path
        self.browser_path = browser_path
        self.base_url = "https://www.drom.ru/reviews/"

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.catalog_extractor = BrandCatalogExtractor(catalog_file, browser_path)
        self.db_parser = NormalizedDatabaseParser(database_path)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)

        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(log_dir / "catalog_parser.log"),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger(__name__)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥
        self.catalog = self.load_catalog()

    def load_catalog(self) -> Optional[CatalogData]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤"""
        if not self.catalog_file.exists():
            self.logger.error(f"–ö–∞—Ç–∞–ª–æ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.catalog_file}")
            self.logger.info(
                "–ó–∞–ø—É—Å—Ç–∏—Ç–µ brand_catalog_extractor.py --extract –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞"
            )
            return None

        catalog = self.catalog_extractor.load_catalog()
        if catalog:
            self.logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω –∫–∞—Ç–∞–ª–æ–≥ —Å {catalog.total_brands} –±—Ä–µ–Ω–¥–∞–º–∏")

        return catalog

    def get_brand_models(self, brand_slug: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –±—Ä–µ–Ω–¥–∞"""
        if not self.catalog or brand_slug not in self.catalog.brands:
            return []

        brand = self.catalog.brands[brand_slug]
        return brand.models if brand.models else []

    def extract_review_urls_from_model_page(
        self, brand_slug: str, model_slug: str, max_pages: int = 5
    ) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL –æ—Ç–∑—ã–≤–æ–≤ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–æ–¥–µ–ª–∏"""
        review_urls = []

        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(
                    executable_path=self.browser_path,
                    headless=True,
                    args=["--no-sandbox", "--disable-dev-shm-usage"],
                )

                page = browser.new_page()

                # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –º–æ–¥–µ–ª–∏
                model_url = f"{self.base_url}{brand_slug}/{model_slug}/"
                self.logger.info(f"–ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–∑—ã–≤—ã: {model_url}")

                for page_num in range(1, max_pages + 1):
                    try:
                        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
                        if page_num == 1:
                            page.goto(model_url, wait_until="networkidle")
                        else:
                            # –î–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                            page_url = f"{model_url}?page={page_num}"
                            page.goto(page_url, wait_until="networkidle")

                        time.sleep(2)

                        # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ—Ç–∑—ã–≤—ã
                        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è Drom
                        review_selectors = [
                            f'a[href*="/reviews/{brand_slug}/{model_slug}/"]',
                            'a[href*="/reviews/"][href*="/"]',
                            ".review-item a",
                            ".reviews-list a",
                        ]

                        found_reviews = False

                        for selector in review_selectors:
                            try:
                                links = page.query_selector_all(selector)

                                for link in links:
                                    href = link.get_attribute("href")
                                    if (
                                        href
                                        and f"/reviews/{brand_slug}/{model_slug}/"
                                        in href
                                        and href.count("/") >= 5
                                    ):  # /reviews/brand/model/id/

                                        full_url = (
                                            href
                                            if href.startswith("http")
                                            else f"https://www.drom.ru{href}"
                                        )

                                        if full_url not in review_urls:
                                            review_urls.append(full_url)
                                            found_reviews = True

                                if found_reviews:
                                    break

                            except Exception as e:
                                self.logger.debug(f"–û—à–∏–±–∫–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ {selector}: {e}")
                                continue

                        # –ï—Å–ª–∏ –æ—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º
                        if page_num == 1 and not found_reviews:
                            self.logger.warning(
                                f"–û—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {brand_slug}/{model_slug}"
                            )
                            break

                        # –ï—Å–ª–∏ –Ω–∞ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º
                        if not found_reviews:
                            break

                    except Exception as e:
                        self.logger.error(f"–û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {e}")
                        break

                browser.close()

        except Exception as e:
            self.logger.error(
                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ URL –¥–ª—è {brand_slug}/{model_slug}: {e}"
            )

        self.logger.info(
            f"–ù–∞–π–¥–µ–Ω–æ {len(review_urls)} –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è {brand_slug}/{model_slug}"
        )
        return review_urls

    def parse_brand_sequential(
        self,
        brand_slug: str,
        max_models: Optional[int] = None,
        max_reviews_per_model: int = 50,
    ) -> ParseResult:
        """–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –±—Ä–µ–Ω–¥–∞"""
        start_time = time.time()

        if not self.catalog or brand_slug not in self.catalog.brands:
            raise ValueError(f"–ë—Ä–µ–Ω–¥ {brand_slug} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–∞—Ç–∞–ª–æ–≥–µ")

        brand = self.catalog.brands[brand_slug]
        models = self.get_brand_models(brand_slug)

        if not models:
            self.logger.warning(f"–ú–æ–¥–µ–ª–∏ –¥–ª—è –±—Ä–µ–Ω–¥–∞ {brand_slug} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return ParseResult(
                brand_slug=brand_slug,
                brand_name=brand.name,
                total_models=0,
                processed_models=0,
                total_reviews=0,
                new_reviews=0,
                skipped_reviews=0,
                error_reviews=0,
                duration_seconds=time.time() - start_time,
                errors=["–ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"],
            )

        if max_models:
            models = models[:max_models]

        self.logger.info(f"üöó –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –±—Ä–µ–Ω–¥–∞ {brand.name} ({brand_slug})")
        self.logger.info(f"üìã –ú–æ–¥–µ–ª–µ–π –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(models)}")

        result = ParseResult(
            brand_slug=brand_slug,
            brand_name=brand.name,
            total_models=len(models),
            processed_models=0,
            total_reviews=0,
            new_reviews=0,
            skipped_reviews=0,
            error_reviews=0,
            duration_seconds=0,
            errors=[],
        )

        for i, model_slug in enumerate(models, 1):
            self.logger.info(f"[{i}/{len(models)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å: {model_slug}")

            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
                review_urls = self.extract_review_urls_from_model_page(
                    brand_slug, model_slug, max_pages=3
                )

                if not review_urls:
                    self.logger.warning(f"–û—Ç–∑—ã–≤—ã –¥–ª—è {model_slug} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    continue

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
                if len(review_urls) > max_reviews_per_model:
                    review_urls = review_urls[:max_reviews_per_model]

                result.total_reviews += len(review_urls)

                # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π –æ—Ç–∑—ã–≤
                for j, review_url in enumerate(review_urls, 1):
                    try:
                        self.logger.info(
                            f"  [{j}/{len(review_urls)}] –ü–∞—Ä—Å–∏–º: {review_url}"
                        )

                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø–∞—Ä—Å–µ—Ä
                        success = self.db_parser.parse_single_review(review_url)

                        if success:
                            result.new_reviews += 1
                        else:
                            result.skipped_reviews += 1

                        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –æ—Ç–∑—ã–≤–∞–º–∏
                        time.sleep(1)

                    except Exception as e:
                        self.logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–∞ {review_url}: {e}")
                        result.error_reviews += 1
                        result.errors.append(f"{review_url}: {str(e)}")

                result.processed_models += 1

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
                time.sleep(2)

            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–¥–µ–ª–∏ {model_slug}: {e}")
                result.errors.append(f"–ú–æ–¥–µ–ª—å {model_slug}: {str(e)}")

        result.duration_seconds = time.time() - start_time

        self.logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ {brand.name} –∑–∞–≤–µ—Ä—à–µ–Ω:")
        self.logger.info(
            f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {result.processed_models}/{result.total_models}"
        )
        self.logger.info(f"   –ù–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {result.new_reviews}")
        self.logger.info(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {result.skipped_reviews}")
        self.logger.info(f"   –û—à–∏–±–æ–∫: {result.error_reviews}")
        self.logger.info(f"   –í—Ä–µ–º—è: {result.duration_seconds:.1f} —Å–µ–∫")

        return result

    def parse_all_brands_sequential(
        self,
        max_brands: Optional[int] = None,
        max_models_per_brand: int = 10,
        max_reviews_per_model: int = 20,
    ) -> List[ParseResult]:
        """–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –±—Ä–µ–Ω–¥–æ–≤"""
        if not self.catalog:
            raise ValueError("–ö–∞—Ç–∞–ª–æ–≥ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –±—Ä–µ–Ω–¥—ã –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ—Ç–∑—ã–≤–æ–≤ (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
        brands_sorted = sorted(
            self.catalog.brands.values(), key=lambda x: x.review_count, reverse=True
        )

        if max_brands:
            brands_sorted = brands_sorted[:max_brands]

        self.logger.info(f"üåü –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ {len(brands_sorted)} –±—Ä–µ–Ω–¥–æ–≤")

        results = []

        for i, brand in enumerate(brands_sorted, 1):
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"–ë–†–ï–ù–î {i}/{len(brands_sorted)}: {brand.name}")
            self.logger.info(f"{'='*60}")

            try:
                result = self.parse_brand_sequential(
                    brand.slug,
                    max_models=max_models_per_brand,
                    max_reviews_per_model=max_reviews_per_model,
                )
                results.append(result)

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±—Ä–µ–Ω–¥–∞–º–∏
                time.sleep(5)

            except Exception as e:
                self.logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {brand.name}: {e}")

                error_result = ParseResult(
                    brand_slug=brand.slug,
                    brand_name=brand.name,
                    total_models=0,
                    processed_models=0,
                    total_reviews=0,
                    new_reviews=0,
                    skipped_reviews=0,
                    error_reviews=0,
                    duration_seconds=0,
                    errors=[str(e)],
                )
                results.append(error_result)

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.print_final_stats(results)

        return results

    def print_final_stats(self, results: List[ParseResult]):
        """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        total_brands = len(results)
        total_models = sum(r.processed_models for r in results)
        total_reviews = sum(r.new_reviews for r in results)
        total_skipped = sum(r.skipped_reviews for r in results)
        total_errors = sum(r.error_reviews for r in results)
        total_time = sum(r.duration_seconds for r in results)

        self.logger.info(f"\n{'='*60}")
        self.logger.info("üéâ –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê")
        self.logger.info(f"{'='*60}")
        self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {total_brands}")
        self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {total_models}")
        self.logger.info(f"–ù–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {total_reviews}")
        self.logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {total_skipped}")
        self.logger.info(f"–û—à–∏–±–æ–∫: {total_errors}")
        self.logger.info(f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω")

        # –¢–æ–ø –±—Ä–µ–Ω–¥–æ–≤ –ø–æ –Ω–æ–≤—ã–º –æ—Ç–∑—ã–≤–∞–º
        top_results = sorted(results, key=lambda x: x.new_reviews, reverse=True)[:10]

        self.logger.info(f"\nüèÜ –¢–û–ü-10 –ë–†–ï–ù–î–û–í –ü–û –ù–û–í–´–ú –û–¢–ó–´–í–ê–ú:")
        for i, result in enumerate(top_results, 1):
            self.logger.info(
                f"{i:2d}. {result.brand_name:15} - {result.new_reviews:4d} –æ—Ç–∑—ã–≤–æ–≤"
            )

    def get_database_stats(self) -> dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        return self.db_parser.get_database_stats()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse

    parser = argparse.ArgumentParser(description="–ö–∞—Ç–∞–ª–æ–∂–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –æ—Ç–∑—ã–≤–æ–≤ Drom.ru")
    parser.add_argument("--brand", type=str, help="–ü–∞—Ä—Å–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±—Ä–µ–Ω–¥")
    parser.add_argument("--all-brands", action="store_true", help="–ü–∞—Ä—Å–∏—Ç—å –≤—Å–µ –±—Ä–µ–Ω–¥—ã")
    parser.add_argument("--max-brands", type=int, default=10, help="–ú–∞–∫—Å–∏–º—É–º –±—Ä–µ–Ω–¥–æ–≤")
    parser.add_argument(
        "--max-models", type=int, default=5, help="–ú–∞–∫—Å–∏–º—É–º –º–æ–¥–µ–ª–µ–π –Ω–∞ –±—Ä–µ–Ω–¥"
    )
    parser.add_argument(
        "--max-reviews", type=int, default=10, help="–ú–∞–∫—Å–∏–º—É–º –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –º–æ–¥–µ–ª—å"
    )
    parser.add_argument("--stats", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ë–î")

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    catalog_parser = CatalogBasedParser()

    if not catalog_parser.catalog:
        print("‚ùå –ö–∞—Ç–∞–ª–æ–≥ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω!")
        print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python brand_catalog_extractor.py --extract")
        return

    if args.stats:
        stats = catalog_parser.get_database_stats()
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
        for key, value in stats.items():
            print(f"{key}: {value}")

    elif args.brand:
        print(f"üéØ –ü–∞—Ä—Å–∏–º –±—Ä–µ–Ω–¥: {args.brand}")
        try:
            result = catalog_parser.parse_brand_sequential(
                args.brand,
                max_models=args.max_models,
                max_reviews_per_model=args.max_reviews,
            )
            print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {result.new_reviews} –Ω–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

    elif args.all_brands:
        print(f"üåü –ü–∞—Ä—Å–∏–º –≤—Å–µ –±—Ä–µ–Ω–¥—ã (–º–∞–∫—Å. {args.max_brands})")
        try:
            results = catalog_parser.parse_all_brands_sequential(
                max_brands=args.max_brands,
                max_models_per_brand=args.max_models,
                max_reviews_per_model=args.max_reviews,
            )
            total_reviews = sum(r.new_reviews for r in results)
            print(f"‚úÖ –ò—Ç–æ–≥–æ –Ω–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {total_reviews}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

    else:
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --brand BRAND, --all-brands –∏–ª–∏ --stats")
        print("\n–ü—Ä–∏–º–µ—Ä—ã:")
        print("python catalog_parser.py --brand toyota --max-models 3 --max-reviews 5")
        print("python catalog_parser.py --all-brands --max-brands 5 --max-models 2")
        print("python catalog_parser.py --stats")


if __name__ == "__main__":
    main()
