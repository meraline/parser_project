#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ –ø–µ—Ä–≤—ã—Ö 3 –º–æ–¥–µ–ª–µ–π –ø–æ 3 –¥–ª–∏–Ω–Ω—ã—Ö –∏ 10 –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤
—Å–æ –≤—Å–µ–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –∏ –¥–∞–Ω–Ω—ã–º–∏
"""

import json
import sys
import os
from datetime import datetime
from typing import List, Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PYTHONPATH
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.auto_reviews_parser.parsers.drom_reviews import DromReviewsParser


def get_first_brands_with_models(limit: int = 3) -> List[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–≤—ã–µ –±—Ä–µ–Ω–¥—ã —Å –∏—Ö –º–æ–¥–µ–ª—è–º–∏
    """
    print(f"üîç –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–µ {limit} –±—Ä–µ–Ω–¥–æ–≤ —Å –º–æ–¥–µ–ª—è–º–∏...")
    
    parser = DromReviewsParser()
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥–æ–≤
    brands_url = "https://www.drom.ru/reviews/"
    try:
        response = parser.session.get(brands_url, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ù–∞—Ö–æ–¥–∏–º –±–ª–æ–∫ —Å –±—Ä–µ–Ω–¥–∞–º–∏
        brands_container = soup.find('div', {'data-ftid': 'component_cars-list'})
        if not brands_container:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –±—Ä–µ–Ω–¥–∞–º–∏")
            return []
        
        brands_links = brands_container.find_all('a', {'data-ftid': 'component_cars-list-item_hidden-link'})
        
        result_brands = []
        
        for i, brand_link in enumerate(brands_links[:limit]):
            if len(result_brands) >= limit:
                break
                
            brand_url = brand_link.get('href')
            brand_name = brand_link.text.strip()
            
            if not brand_url or not brand_name:
                continue
                
            print(f"üìã –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±—Ä–µ–Ω–¥ {i+1}/{limit}: {brand_name}")
            
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –±—Ä–µ–Ω–¥–∞
            try:
                models_response = parser.session.get(brand_url, timeout=30)
                models_response.raise_for_status()
                
                models_soup = BeautifulSoup(models_response.content, 'html.parser')
                
                # –ù–∞—Ö–æ–¥–∏–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–æ–¥–µ–ª–∏
                model_links = models_soup.find_all('a', href=True)
                models = []
                
                for model_link in model_links:
                    href = model_link.get('href', '')
                    if '/reviews/' in href and '/' in href.split('/reviews/')[-1]:
                        model_path = href.split('/reviews/')[-1]
                        if model_path.count('/') >= 1:  # brand/model/
                            parts = model_path.strip('/').split('/')
                            if len(parts) >= 2:
                                model_name = parts[1]
                                if model_name and model_name not in [m['name'] for m in models]:
                                    models.append({
                                        'name': model_name,
                                        'url': href,
                                        'brand': parts[0]
                                    })
                
                if models:
                    result_brands.append({
                        'name': brand_name,
                        'url': brand_url,
                        'models': models[:3]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 –º–æ–¥–µ–ª–∏
                    })
                    print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(models[:3])} –º–æ–¥–µ–ª–µ–π")
                else:
                    print(f"  ‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
                continue
        
        return result_brands
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤: {e}")
        return []


def parse_model_reviews(parser: DromReviewsParser, model: Dict[str, Any], 
                       long_limit: int = 3, short_limit: int = 10) -> Dict[str, Any]:
    """
    –ü–∞—Ä—Å–∏—Ç –æ—Ç–∑—ã–≤—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    model_name = model['name']
    model_url = model['url']
    brand_name = model['brand']
    
    print(f"  üöó –ü–∞—Ä—Å–∏–º –º–æ–¥–µ–ª—å: {brand_name}/{model_name}")
    
    result = {
        'brand': brand_name,
        'model': model_name,
        'url': model_url,
        'long_reviews': [],
        'short_reviews': [],
        'parsed_at': datetime.now().isoformat(),
        'stats': {
            'long_reviews_found': 0,
            'short_reviews_found': 0,
            'total_reviews': 0
        }
    }
    
    try:
        # –ü–∞—Ä—Å–∏–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
        print(f"    üìù –ü–∞—Ä—Å–∏–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã (–ª–∏–º–∏—Ç: {long_limit})...")
        long_reviews = parser.parse_long_reviews(model_url, limit=long_limit)
        
        # –î–µ—Ç–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
        detailed_long_reviews = []
        for review in long_reviews[:long_limit]:
            try:
                detailed_review = parser.parse_review_details(review.get('url', ''))
                if detailed_review:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –¥–µ—Ç–∞–ª–∏
                    full_review = {**review, **detailed_review}
                    detailed_long_reviews.append(full_review)
                    print(f"      ‚úÖ –î–ª–∏–Ω–Ω—ã–π –æ—Ç–∑—ã–≤: {full_review.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:50]}...")
            except Exception as e:
                print(f"      ‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞: {e}")
                detailed_long_reviews.append(review)
        
        result['long_reviews'] = detailed_long_reviews
        result['stats']['long_reviews_found'] = len(detailed_long_reviews)
        
        # –ü–∞—Ä—Å–∏–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–∑—ã–≤—ã
        print(f"    üí¨ –ü–∞—Ä—Å–∏–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–∑—ã–≤—ã (–ª–∏–º–∏—Ç: {short_limit})...")
        short_reviews = parser.parse_short_reviews(model_url, limit=short_limit)
        
        result['short_reviews'] = short_reviews[:short_limit]
        result['stats']['short_reviews_found'] = len(short_reviews[:short_limit])
        result['stats']['total_reviews'] = result['stats']['long_reviews_found'] + result['stats']['short_reviews_found']
        
        print(f"    üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {result['stats']['long_reviews_found']} –¥–ª–∏–Ω–Ω—ã—Ö + {result['stats']['short_reviews_found']} –∫–æ—Ä–æ—Ç–∫–∏—Ö = {result['stats']['total_reviews']} –æ—Ç–∑—ã–≤–æ–≤")
        
    except Exception as e:
        print(f"    ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
    
    return result


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
    """
    print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–¶–ï–ù–ù–û–ì–û –ü–ê–†–°–ò–ù–ì–ê DROM.RU")
    print("=" * 60)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –±—Ä–µ–Ω–¥–∞ —Å –º–æ–¥–µ–ª—è–º–∏
    brands = get_first_brands_with_models(3)
    
    if not brands:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –±—Ä–µ–Ω–¥—ã")
        return
    
    print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ {len(brands)} –±—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = DromReviewsParser()
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞
    parsing_results = {
        'started_at': datetime.now().isoformat(),
        'brands_processed': [],
        'total_stats': {
            'brands': 0,
            'models': 0,
            'long_reviews': 0,
            'short_reviews': 0,
            'total_reviews': 0
        }
    }
    
    # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π –±—Ä–µ–Ω–¥
    for brand_idx, brand in enumerate(brands):
        print(f"\nüè¢ –ë–†–ï–ù–î {brand_idx + 1}/3: {brand['name']}")
        print("-" * 40)
        
        brand_result = {
            'name': brand['name'],
            'url': brand['url'],
            'models': [],
            'stats': {
                'models_processed': 0,
                'long_reviews': 0,
                'short_reviews': 0,
                'total_reviews': 0
            }
        }
        
        # –ü–∞—Ä—Å–∏–º –º–æ–¥–µ–ª–∏ –±—Ä–µ–Ω–¥–∞
        for model_idx, model in enumerate(brand['models'][:3]):
            print(f"\n  üöó –ú–û–î–ï–õ–¨ {model_idx + 1}/{len(brand['models'][:3])}: {model['name']}")
            
            model_result = parse_model_reviews(parser, model, long_limit=3, short_limit=10)
            brand_result['models'].append(model_result)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±—Ä–µ–Ω–¥–∞
            brand_result['stats']['models_processed'] += 1
            brand_result['stats']['long_reviews'] += model_result['stats']['long_reviews_found']
            brand_result['stats']['short_reviews'] += model_result['stats']['short_reviews_found']
            brand_result['stats']['total_reviews'] += model_result['stats']['total_reviews']
        
        parsing_results['brands_processed'].append(brand_result)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        parsing_results['total_stats']['brands'] += 1
        parsing_results['total_stats']['models'] += brand_result['stats']['models_processed']
        parsing_results['total_stats']['long_reviews'] += brand_result['stats']['long_reviews']
        parsing_results['total_stats']['short_reviews'] += brand_result['stats']['short_reviews']
        parsing_results['total_stats']['total_reviews'] += brand_result['stats']['total_reviews']
        
        print(f"\n  üìä –ò–¢–û–ì–û –ü–û –ë–†–ï–ù–î–£ {brand['name']}:")
        print(f"     –ú–æ–¥–µ–ª–µ–π: {brand_result['stats']['models_processed']}")
        print(f"     –î–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {brand_result['stats']['long_reviews']}")
        print(f"     –ö–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤: {brand_result['stats']['short_reviews']}")
        print(f"     –í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {brand_result['stats']['total_reviews']}")
    
    # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥
    parsing_results['completed_at'] = datetime.now().isoformat()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_file = f"data/exports/full_parsing_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(parsing_results, f, ensure_ascii=False, indent=2)
    
    # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n" + "=" * 60)
    print("üéâ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù! –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print("=" * 60)
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {parsing_results['total_stats']['brands']}")
    print(f"üöó –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {parsing_results['total_stats']['models']}")
    print(f"üìù –î–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {parsing_results['total_stats']['long_reviews']}")
    print(f"üí¨ –ö–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤: {parsing_results['total_stats']['short_reviews']}")
    print(f"üìã –í–°–ï–ì–û –û–¢–ó–´–í–û–í: {parsing_results['total_stats']['total_reviews']}")
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    if parsing_results['brands_processed']:
        print("\n" + "=" * 60)
        print("üìã –ü–†–ò–ú–ï–†–´ –ò–ó–í–õ–ï–ß–ï–ù–ù–´–• –î–ê–ù–ù–´–•:")
        print("=" * 60)
        
        for brand in parsing_results['brands_processed'][:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2 –±—Ä–µ–Ω–¥–∞
            print(f"\nüè¢ –ë–†–ï–ù–î: {brand['name']}")
            
            for model in brand['models'][:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2 –º–æ–¥–µ–ª–∏
                print(f"\n  üöó –ú–û–î–ï–õ–¨: {model['model']}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞
                if model['long_reviews']:
                    long_review = model['long_reviews'][0]
                    print(f"    üìù –î–õ–ò–ù–ù–´–ô –û–¢–ó–´–í:")
                    print(f"       –ó–∞–≥–æ–ª–æ–≤–æ–∫: {long_review.get('title', '–ù/–î')}")
                    print(f"       –ê–≤—Ç–æ—Ä: {long_review.get('author', '–ù/–î')}")
                    print(f"       –ì–æ—Ä–æ–¥: {long_review.get('city', '–ù/–î')}")
                    print(f"       –î–∞—Ç–∞: {long_review.get('date', '–ù/–î')}")
                    print(f"       –ü–ª—é—Å—ã: {long_review.get('pros', '–ù/–î')[:100]}...")
                    print(f"       –ú–∏–Ω—É—Å—ã: {long_review.get('cons', '–ù/–î')[:100]}...")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ—Ç–∑—ã–≤–∞
                if model['short_reviews']:
                    short_review = model['short_reviews'][0]
                    print(f"    üí¨ –ö–û–†–û–¢–ö–ò–ô –û–¢–ó–´–í:")
                    print(f"       –ê–≤—Ç–æ—Ä: {short_review.get('author', '–ù/–î')}")
                    print(f"       –ì–æ—Ä–æ–¥: {short_review.get('city', '–ù/–î')}")
                    print(f"       –ì–æ–¥: {short_review.get('year', '–ù/–î')}")
                    print(f"       –û–±—ä–µ–º: {short_review.get('volume', '–ù/–î')}")
                    print(f"       –ü–ª—é—Å—ã: {short_review.get('positive', '–ù/–î')[:100]}...")
    
    print("\n‚úÖ –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")


if __name__ == "__main__":
    main()
