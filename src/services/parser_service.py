from __future__ import annotations

import json
import logging

from auto_reviews_parser import AutoReviewsParser, Config

from .queue_service import QueueService
from .export_service import ExportService
from ..utils.cache import RedisCache


logger = logging.getLogger(__name__)


class ParserService:
    """–°–µ—Ä–≤–∏—Å-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–µ—Ä–æ–≤"""

    def __init__(
        self, db_path: str = Config.DB_PATH, cache: RedisCache | None = None
    ):
        self.queue_service = QueueService(db_path, Config.TARGET_BRANDS)
        self.export_service = ExportService(db_path)
        self.parser = AutoReviewsParser(db_path, queue_service=self.queue_service)
        self.cache = cache

    def get_status_data(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –±–∞–∑—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∞."""
        cache_key = "parser_status"
        if self.cache:
            cached = self.cache.get(cache_key)
            if cached:
                return json.loads(cached)
        stats = self.parser.db.get_parsing_stats()
        queue_stats = self.queue_service.get_queue_stats()
        data = {"stats": stats, "queue_stats": queue_stats}
        if self.cache:
            self.cache.set(cache_key, json.dumps(data))
        return data

    def show_status(self) -> None:
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –æ—á–µ—Ä–µ–¥–∏"""
        data = self.get_status_data()
        stats = data["stats"]
        logger.info("\nüìä –°–¢–ê–¢–£–° –ë–ê–ó–´ –î–ê–ù–ù–´–•")
        logger.info("=" * 50)
        logger.info(f"–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {stats['total_reviews']:,}")
        logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤: {stats['unique_brands']}")
        logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {stats['unique_models']}")

        if stats["by_source"]:
            logger.info("\n–ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
            for source, count in stats["by_source"].items():
                logger.info(f"  {source}: {count:,}")

        if stats["by_type"]:
            logger.info("\n–ü–æ —Ç–∏–ø–∞–º:")
            for type_name, count in stats["by_type"].items():
                logger.info(f"  {type_name}: {count:,}")

        queue_stats = data["queue_stats"]
        logger.info("\nüìã –°–¢–ê–¢–£–° –û–ß–ï–†–ï–î–ò")
        logger.info("=" * 50)
        total_sources = sum(queue_stats.values())
        for status, count in queue_stats.items():
            percentage = (count / total_sources * 100) if total_sources > 0 else 0
            logger.info(f"{status}: {count} ({percentage:.1f}%)")
        logger.info(f"–í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {total_sources}")

    def reset_queue(self) -> None:
        """–°–±—Ä–æ—Å –æ—á–µ—Ä–µ–¥–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        logger.info("üîÑ –°–±—Ä–æ—Å –æ—á–µ—Ä–µ–¥–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        self.queue_service.initialize_queue()

    def export_data(self, output_format: str = "xlsx") -> None:
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã"""
        self.export_service.export_data(output_format)
