"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø–∞—Ä—Å–µ—Ä–∞–º–∏ –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π
–°–≤—è–∑—ã–≤–∞–µ—Ç –∫–∞—Ç–∞–ª–æ–≥–Ω—ã–µ –ø–∞—Ä—Å–µ—Ä—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π PostgreSQL —Å—Ö–µ–º–æ–π
"""

import asyncio
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø–∞—Ä—Å–µ—Ä–∞–º–∏
import sys
sys.path.append('/home/analityk/–î–æ–∫—É–º–µ–Ω—Ç—ã/projects/parser_project')

try:
    from scripts.parsing.brand_catalog_extractor import BrandCatalogExtractor, BrandInfo, CatalogData
    from src.auto_reviews_parser.database.extended_postgres_manager import (
        ExtendedPostgresManager, BrandData, ModelData, ShortReviewData, ParseSessionData
    )
    from src.auto_reviews_parser.parsers.drom_reviews import DromReviewsParser
except ImportError as e:
    logging.warning(f"–ò–º–ø–æ—Ä—Ç –ø–∞—Ä—Å–µ—Ä–æ–≤ –Ω–µ —É–¥–∞–ª—Å—è: {e}")


@dataclass
class CatalogIntegrationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∫–∞—Ç–∞–ª–æ–≥–∞"""
    –Ω–æ–≤—ã—Ö_–±—Ä–µ–Ω–¥–æ–≤: int
    –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö_–±—Ä–µ–Ω–¥–æ–≤: int
    –Ω–æ–≤—ã—Ö_–º–æ–¥–µ–ª–µ–π: int
    –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö_–º–æ–¥–µ–ª–µ–π: int
    –æ—à–∏–±–æ–∫: int
    –¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫: List[str]


class CatalogIntegrator:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–∞—Ç–∞–ª–æ–≥–æ–º –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, postgres_manager: ExtendedPostgresManager):
        self.postgres_manager = postgres_manager
        self.logger = logging.getLogger(__name__)
        self.catalog_extractor = BrandCatalogExtractor()
    
    async def extract_and_import_catalog(self, force_update: bool = False) -> CatalogIntegrationResult:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞ —Å drom.ru –∏ –∏–º–ø–æ—Ä—Ç –≤ PostgreSQL
        
        Args:
            force_update: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–∂–µ –µ—Å–ª–∏ –∫–∞—Ç–∞–ª–æ–≥ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        """
        result = CatalogIntegrationResult(
            –Ω–æ–≤—ã—Ö_–±—Ä–µ–Ω–¥–æ–≤=0, –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö_–±—Ä–µ–Ω–¥–æ–≤=0,
            –Ω–æ–≤—ã—Ö_–º–æ–¥–µ–ª–µ–π=0, –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö_–º–æ–¥–µ–ª–µ–π=0,
            –æ—à–∏–±–æ–∫=0, –¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫=[]
        )
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å–µ—Å—Å–∏—é –ø–∞—Ä—Å–∏–Ω–≥–∞
        session_data = ParseSessionData(
            —Ç–∏–ø_–ø–∞—Ä—Å–∏–Ω–≥–∞='catalog',
            –≤–µ—Ä—Å–∏—è_–ø–∞—Ä—Å–µ—Ä–∞='2.0'
        )
        session_id = await self.postgres_manager.start_parse_session(session_data)
        
        try:
            self.logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∏–º–ø–æ—Ä—Ç –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥
            catalog_data = await self._extract_catalog_data(force_update)
            if not catalog_data:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∞")
            
            self.logger.info(f"üì¶ –ò–∑–≤–ª–µ—á–µ–Ω –∫–∞—Ç–∞–ª–æ–≥: {catalog_data.total_brands} –±—Ä–µ–Ω–¥–æ–≤")
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±—Ä–µ–Ω–¥—ã –∏ –º–æ–¥–µ–ª–∏
            await self._import_brands_and_models(catalog_data, result)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é
            await self.postgres_manager.update_parse_session(session_id, {
                '–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ_—Å—Ç—Ä–∞–Ω–∏—Ü': 1,
                '–Ω–∞–π–¥–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤': catalog_data.total_brands,
                '—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤': result.–Ω–æ–≤—ã—Ö_–±—Ä–µ–Ω–¥–æ–≤ + result.–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö_–±—Ä–µ–Ω–¥–æ–≤,
                '–æ—à–∏–±–æ–∫': result.–æ—à–∏–±–æ–∫
            })
            
            await self.postgres_manager.finish_parse_session(session_id, '–∑–∞–≤–µ—Ä—à–µ–Ω')
            
            self.logger.info("‚úÖ –ò–º–ø–æ—Ä—Ç –∫–∞—Ç–∞–ª–æ–≥–∞ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
            result.–æ—à–∏–±–æ–∫ += 1
            result.–¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫.append(str(e))
            
            await self.postgres_manager.finish_parse_session(
                session_id, '–æ—à–∏–±–∫–∞', str(e)
            )
        
        return result
    
    async def _extract_catalog_data(self, force_update: bool) -> Optional[CatalogData]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–∞—Ç–∞–ª–æ–≥–∞"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞
        cache_file = Path('data/brand_catalog.json')
        
        if cache_file.exists() and not force_update:
            self.logger.info("üìÇ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥")
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return CatalogData(
                        extraction_date=datetime.fromisoformat(data['extraction_date']),
                        total_brands=data['total_brands'],
                        brands=[BrandInfo(**brand) for brand in data['brands']]
                    )
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–µ—à–∞: {e}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—ã–π –∫–∞—Ç–∞–ª–æ–≥
        self.logger.info("üåê –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–≤–µ–∂–∏–π –∫–∞—Ç–∞–ª–æ–≥ —Å drom.ru")
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
            catalog_data = self.catalog_extractor.extract_full_catalog()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
            if catalog_data:
                self._save_catalog_to_cache(catalog_data, cache_file)
            
            return catalog_data
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
            return None
    
    def _save_catalog_to_cache(self, catalog_data: CatalogData, cache_file: Path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –≤ –∫–µ—à"""
        try:
            cache_file.parent.mkdir(parents=True, exist_ok=True)
            
            data = {
                'extraction_date': catalog_data.extraction_date.isoformat(),
                'total_brands': catalog_data.total_brands,
                'brands': [
                    {
                        'name': brand.name,
                        'slug': brand.slug,
                        'url': brand.url,
                        'review_count': brand.review_count,
                        'models': brand.models
                    }
                    for brand in catalog_data.brands
                ]
            }
            
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"üíæ –ö–∞—Ç–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –∫–µ—à: {cache_file}")
            
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞: {e}")
    
    async def _import_brands_and_models(self, catalog_data: CatalogData, result: CatalogIntegrationResult):
        """–ò–º–ø–æ—Ä—Ç –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π –≤ PostgreSQL"""
        
        for brand_info in catalog_data.brands:
            try:
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±—Ä–µ–Ω–¥
                brand_data = BrandData(
                    –Ω–∞–∑–≤–∞–Ω–∏–µ=brand_info.name,
                    –Ω–∞–∑–≤–∞–Ω–∏–µ_–≤_url=brand_info.slug,
                    url=brand_info.url,
                    –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–æ—Ç–∑—ã–≤–æ–≤=brand_info.review_count
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –±—Ä–µ–Ω–¥–∞
                existing_brand = await self.postgres_manager.get_brand_by_slug(brand_info.slug)
                
                brand_id = await self.postgres_manager.insert_brand(brand_data)
                
                if existing_brand:
                    result.–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö_–±—Ä–µ–Ω–¥–æ–≤ += 1
                    self.logger.debug(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω –±—Ä–µ–Ω–¥: {brand_info.name}")
                else:
                    result.–Ω–æ–≤—ã—Ö_–±—Ä–µ–Ω–¥–æ–≤ += 1
                    self.logger.debug(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω –±—Ä–µ–Ω–¥: {brand_info.name}")
                
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –±—Ä–µ–Ω–¥–∞
                await self._import_brand_models(brand_id, brand_info, result)
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –±—Ä–µ–Ω–¥–∞ {brand_info.name}: {e}")
                result.–æ—à–∏–±–æ–∫ += 1
                result.–¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫.append(f"–ë—Ä–µ–Ω–¥ {brand_info.name}: {e}")
    
    async def _import_brand_models(self, brand_id: int, brand_info: BrandInfo, result: CatalogIntegrationResult):
        """–ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞"""
        
        for model_slug in brand_info.models:
            try:
                # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
                model_data = ModelData(
                    –±—Ä–µ–Ω–¥_id=brand_id,
                    –Ω–∞–∑–≤–∞–Ω–∏–µ=model_slug.replace('_', ' ').title(),  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                    –Ω–∞–∑–≤–∞–Ω–∏–µ_–≤_url=model_slug,
                    url=f"{brand_info.url.rstrip('/')}/{model_slug}/"
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
                existing_model = await self.postgres_manager.get_model_by_brand_and_slug(
                    brand_id, model_slug
                )
                
                model_id = await self.postgres_manager.insert_model(model_data)
                
                if existing_model:
                    result.–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö_–º–æ–¥–µ–ª–µ–π += 1
                else:
                    result.–Ω–æ–≤—ã—Ö_–º–æ–¥–µ–ª–µ–π += 1
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥–µ–ª–∏ {model_slug}: {e}")
                result.–æ—à–∏–±–æ–∫ += 1
                result.–¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫.append(f"–ú–æ–¥–µ–ª—å {model_slug}: {e}")


class ShortReviewsIntegrator:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –æ—Ç–∑—ã–≤–∞–º–∏"""
    
    def __init__(self, postgres_manager: ExtendedPostgresManager):
        self.postgres_manager = postgres_manager
        self.logger = logging.getLogger(__name__)
        self.drom_parser = DromReviewsParser()
    
    async def parse_and_import_short_reviews(self, model_id: int, model_url: str, 
                                           max_pages: int = 10) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –∏ –∏–º–ø–æ—Ä—Ç –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
        
        Args:
            model_id: ID –º–æ–¥–µ–ª–∏ –≤ PostgreSQL
            model_url: URL –º–æ–¥–µ–ª–∏ –Ω–∞ drom.ru
            max_pages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        result = {
            '–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ_—Å—Ç—Ä–∞–Ω–∏—Ü': 0,
            '–Ω–∞–π–¥–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤': 0,
            '—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤': 0,
            '–æ—à–∏–±–æ–∫': 0,
            '–¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫': []
        }
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å–µ—Å—Å–∏—é –ø–∞—Ä—Å–∏–Ω–≥–∞
        session_data = ParseSessionData(
            —Ç–∏–ø_–ø–∞—Ä—Å–∏–Ω–≥–∞='short_reviews',
            –º–æ–¥–µ–ª—å_id=model_id,
            –≤–µ—Ä—Å–∏—è_–ø–∞—Ä—Å–µ—Ä–∞='2.0'
        )
        session_id = await self.postgres_manager.start_parse_session(session_data)
        
        try:
            self.logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤
            short_reviews_url = f"{model_url.rstrip('/')}/5kopeek/"
            
            # –ü–∞—Ä—Å–∏–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–∑—ã–≤—ã
            for page in range(1, max_pages + 1):
                try:
                    page_url = f"{short_reviews_url}?page={page}"
                    self.logger.debug(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}: {page_url}")
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø–∞—Ä—Å–µ—Ä
                    short_reviews = self.drom_parser.parse_short_reviews(page_url)
                    
                    if not short_reviews:
                        self.logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} –ø—É—Å—Ç–∞, –∑–∞–≤–µ—Ä—à–∞–µ–º")
                        break
                    
                    result['–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ_—Å—Ç—Ä–∞–Ω–∏—Ü'] += 1
                    result['–Ω–∞–π–¥–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤'] += len(short_reviews)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–∑—ã–≤—ã
                    for review_data in short_reviews:
                        try:
                            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω–∞—à—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                            short_review = await self._convert_review_data(
                                review_data, model_id
                            )
                            
                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞–≤—Ç–æ—Ä–∞
                            author_id = None
                            if review_data.get('author_name'):
                                author_id = await self.postgres_manager.get_or_create_author(
                                    –ø—Å–µ–≤–¥–æ–Ω–∏–º=review_data['author_name'],
                                    –≥–æ—Ä–æ–¥=review_data.get('author_city')
                                )
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–∑—ã–≤
                            review_id = await self.postgres_manager.insert_short_review(
                                short_review, author_id
                            )
                            
                            if review_id:
                                result['—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤'] += 1
                            
                        except Exception as e:
                            result['–æ—à–∏–±–æ–∫'] += 1
                            result['–¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫'].append(f"–û—Ç–∑—ã–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: {e}")
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å —Å–µ—Å—Å–∏–∏
                    await self.postgres_manager.update_parse_session(session_id, {
                        '–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ_—Å—Ç—Ä–∞–Ω–∏—Ü': result['–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ_—Å—Ç—Ä–∞–Ω–∏—Ü'],
                        '–Ω–∞–π–¥–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤': result['–Ω–∞–π–¥–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤'],
                        '—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤': result['—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ_–æ—Ç–∑—ã–≤–æ–≤'],
                        '–æ—à–∏–±–æ–∫': result['–æ—à–∏–±–æ–∫']
                    })
                    
                except Exception as e:
                    self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                    result['–æ—à–∏–±–æ–∫'] += 1
                    result['–¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫'].append(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: {e}")
            
            await self.postgres_manager.finish_parse_session(session_id, '–∑–∞–≤–µ—Ä—à–µ–Ω')
            self.logger.info("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω")
            
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            result['–æ—à–∏–±–æ–∫'] += 1
            result['–¥–µ—Ç–∞–ª–∏_–æ—à–∏–±–æ–∫'].append(str(e))
            
            await self.postgres_manager.finish_parse_session(
                session_id, '–æ—à–∏–±–∫–∞', str(e)
            )
        
        return result
    
    async def _convert_review_data(self, review_data: Dict, model_id: int) -> ShortReviewData:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞ –≤ –Ω–∞—à—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É"""
        return ShortReviewData(
            –º–æ–¥–µ–ª—å_id=model_id,
            –≤–Ω–µ—à–Ω–∏–π_id=str(review_data.get('review_id', '')),
            –ø–ª—é—Å—ã=review_data.get('positive_text'),
            –º–∏–Ω—É—Å—ã=review_data.get('negative_text'),
            –ø–æ–ª–æ–º–∫–∏=review_data.get('breakages_text'),
            –≥–æ–¥_–∞–≤—Ç–æ–º–æ–±–∏–ª—è=review_data.get('car_year'),
            –æ–±—ä–µ–º_–¥–≤–∏–≥–∞—Ç–µ–ª—è=review_data.get('car_engine_volume'),
            –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ñ–æ—Ç–æ=review_data.get('photos_count', 0),
            –≥–æ—Ä–æ–¥_–∞–≤—Ç–æ—Ä–∞=review_data.get('author_city'),
            –¥–∞—Ç–∞_–ø—É–±–ª–∏–∫–∞—Ü–∏–∏=review_data.get('publication_date'),
            —Å—Ç–∞—Ç—É—Å_–ø–∞—Ä—Å–∏–Ω–≥–∞='—É—Å–ø–µ—Ö'
        )


# –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
class ParserIntegrationManager:
    """–ì–ª–∞–≤–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–æ–≤ —Å PostgreSQL"""
    
    def __init__(self, postgres_connection_params: Dict[str, Any]):
        self.postgres_manager = ExtendedPostgresManager(postgres_connection_params)
        self.catalog_integrator = CatalogIntegrator(self.postgres_manager)
        self.short_reviews_integrator = ShortReviewsIntegrator(self.postgres_manager)
        self.logger = logging.getLogger(__name__)
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
        await self.postgres_manager.initialize()
        self.logger.info("‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
        await self.postgres_manager.close()
    
    async def full_catalog_integration(self, force_update: bool = False) -> CatalogIntegrationResult:
        """–ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π"""
        return await self.catalog_integrator.extract_and_import_catalog(force_update)
    
    async def integrate_short_reviews_for_model(self, brand_slug: str, model_slug: str, 
                                              max_pages: int = 10) -> Dict[str, Any]:
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        # –ü–æ–ª—É—á–∞–µ–º –±—Ä–µ–Ω–¥ –∏ –º–æ–¥–µ–ª—å
        brand = await self.postgres_manager.get_brand_by_slug(brand_slug)
        if not brand:
            raise ValueError(f"–ë—Ä–µ–Ω–¥ {brand_slug} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        model = await self.postgres_manager.get_model_by_brand_and_slug(
            brand['id'], model_slug
        )
        if not model:
            raise ValueError(f"–ú–æ–¥–µ–ª—å {model_slug} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –ü–∞—Ä—Å–∏–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–∑—ã–≤—ã
        return await self.short_reviews_integrator.parse_and_import_short_reviews(
            model['id'], model['url'], max_pages
        )
    
    async def get_integration_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        return await self.postgres_manager.get_database_stats()


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    
    async def test_integration():
        connection_params = {
            'host': 'localhost',
            'port': 5432,
            'database': 'auto_reviews',
            'user': 'parser',
            'password': 'parser'
        }
        
        manager = ParserIntegrationManager(connection_params)
        
        try:
            await manager.initialize()
            
            # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞
            catalog_result = await manager.full_catalog_integration()
            print("–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∫–∞—Ç–∞–ª–æ–≥–∞:", catalog_result)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = await manager.get_integration_stats()
            print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:", stats)
            
        finally:
            await manager.close()
    
    asyncio.run(test_integration())
