#!/usr/bin/env python3
"""
üöó –ü–ê–†–°–ï–† –û–¢–ó–´–í–û–í DROM.RU - –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
============================================

–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤ —Å —Å–∞–π—Ç–∞ drom.ru —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
- –î–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ (–ø–æ–¥—Ä–æ–±–Ω—ã–µ –æ–±–∑–æ—Ä—ã)
- –ö–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ (–∫—Ä–∞—Ç–∫–∏–µ –º–Ω–µ–Ω–∏—è)
- –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- –ö–∞—Ç–∞–ª–æ–≥–∏–∑–∞—Ü–∏–∏ –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2024
"""

import requests
import json
import time
import logging
import re
from typing import Dict, List, Optional, Tuple
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from ..database.schema import DatabaseManager


class DromReviewsParser:
    """–ü–∞—Ä—Å–µ—Ä –æ—Ç–∑—ã–≤–æ–≤ —Å drom.ru —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–≤—É—Ö —Ç–∏–ø–æ–≤ –æ—Ç–∑—ã–≤–æ–≤"""

    def __init__(self, delay: float = 1.0):
        self.base_url = "https://www.drom.ru"
        self.delay = delay
        self.session = requests.Session()
        self.db_manager = DatabaseManager()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.logger = logging.getLogger(__name__)

        # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è SOCKS –æ—à–∏–±–æ–∫
        self.session.proxies = {}
        
        # Headers –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/91.0.4472.124 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;"
                "q=0.9,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
            }
        )

    def _make_request(self, url: str) -> Optional[BeautifulSoup]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ HTTP –∑–∞–ø—Ä–æ—Å–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            self.logger.info(f"–ó–∞–ø—Ä–æ—Å –∫ {url}")
            response = self.session.get(url, timeout=30)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")
            time.sleep(self.delay)
            return soup

        except requests.RequestException as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {url}: {e}")
            return None

    def parse_long_reviews(
        self, brand_url_name: str, model_url_name: str, max_pages: int = 10
    ) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ (–ø–æ–¥—Ä–æ–±–Ω—ã–µ –æ–±–∑–æ—Ä—ã)
        URL —Ñ–æ—Ä–º–∞—Ç: https://www.drom.ru/reviews/toyota/4runner/
        """
        reviews = []
        page = 1

        while page <= max_pages:
            url = (
                f"{self.base_url}/reviews/{brand_url_name}/"
                f"{model_url_name}/?page={page}"
            )
            soup = self._make_request(url)

            if not soup:
                break

            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –æ—Ç–∑—ã–≤–æ–≤
            review_items = soup.find_all("div", {"data-ftid": "review-item"})

            if not review_items:
                self.logger.info(f"–ù–µ—Ç –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}")
                break

            self.logger.info(
                f"–ù–∞–π–¥–µ–Ω–æ {len(review_items)} " f"–¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}"
            )

            for item in review_items:
                try:
                    review_data = self._extract_long_review_data(item)
                    if review_data:
                        reviews.append(review_data)
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–∑—ã–≤–∞: {e}")
                    continue

            page += 1

        self.logger.info(f"–í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(reviews)} –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤")
        return reviews

    def parse_short_reviews(
        self, brand_url_name: str, model_url_name: str, max_pages: int = 10
    ) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤
        URL —Ñ–æ—Ä–º–∞—Ç: https://www.drom.ru/reviews/toyota/4runner/5kopeek/
        """
        reviews = []
        page = 1

        while page <= max_pages:
            url = (
                f"{self.base_url}/reviews/{brand_url_name}/"
                f"{model_url_name}/5kopeek/?page={page}"
            )
            soup = self._make_request(url)

            if not soup:
                break

            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤
            review_items = soup.find_all("div", {"data-ftid": "short-review-item"})

            if not review_items:
                self.logger.info(f"–ù–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}")
                break

            self.logger.info(
                f"–ù–∞–π–¥–µ–Ω–æ {len(review_items)} " f"–∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}"
            )

            for item in review_items:
                try:
                    review_data = self._extract_short_review_data(item)
                    if review_data:
                        reviews.append(review_data)
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ—Ç–∑—ã–≤–∞: {e}")
                    continue

            page += 1

        self.logger.info(f"–í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(reviews)} –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤")
        return reviews

    def _extract_long_review_data(self, item) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞"""
        try:
            review_data = {}

            # ID –æ—Ç–∑—ã–≤–∞
            review_id = item.get("id")
            if review_id:
                review_data["review_id"] = review_id

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title_elem = item.find("h3")
            if title_elem:
                review_data["title"] = title_elem.get_text(strip=True)

            # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
            content_parts = []

            # –ò—â–µ–º —Å–µ–∫—Ü–∏–∏ —Å —Ç–µ–∫—Å—Ç–æ–º
            content_sections = item.find_all("div", class_="css-6hj46s")
            for section in content_sections:
                text = section.get_text(strip=True)
                if text:
                    content_parts.append(text)

            if content_parts:
                review_data["content"] = "\n".join(content_parts)

            # –ü–ª—é—Å—ã
            positive_elem = item.find("div", {"data-ftid": "review-content__positive"})
            if positive_elem:
                review_data["positive_text"] = positive_elem.get_text(strip=True)

            # –ú–∏–Ω—É—Å—ã
            negative_elem = item.find("div", {"data-ftid": "review-content__negative"})
            if negative_elem:
                review_data["negative_text"] = negative_elem.get_text(strip=True)

            # –ü–æ–ª–æ–º–∫–∏
            breakages_elem = item.find(
                "div", {"data-ftid": "review-content__breakages"}
            )
            if breakages_elem:
                review_data["breakages_text"] = breakages_elem.get_text(strip=True)

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ –∏ –¥–∞—Ç–µ
            author_info = self._extract_author_info(item)
            if author_info:
                review_data.update(author_info)

            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
            car_info = self._extract_car_info(item)
            if car_info:
                review_data.update(car_info)

            # –û—Ü–µ–Ω–∫–∏
            ratings = self._extract_ratings(item)
            if ratings:
                review_data.update(ratings)

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            photos = item.find_all("img")
            review_data["photos_count"] = len(photos) if photos else 0

            return review_data if review_data else None

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞: {e}")
            return None

    def _extract_short_review_data(self, item) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ—Ç–∑—ã–≤–∞"""
        try:
            review_data = {}

            # ID –æ—Ç–∑—ã–≤–∞
            review_id = item.get("id")
            if review_id:
                review_data["review_id"] = review_id

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ
            author_elem = item.find("span", class_="css-1u4ddp")
            if author_elem:
                review_data["author_name"] = author_elem.get_text(strip=True)

            # –ì–æ—Ä–æ–¥
            city_elem = item.find("span", {"data-ftid": "short-review-city"})
            if city_elem:
                review_data["author_city"] = city_elem.get_text(strip=True)

            # –ì–æ–¥ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
            year_elem = item.find("span", {"data-ftid": "short-review-item__year"})
            if year_elem:
                try:
                    review_data["car_year"] = int(year_elem.get_text(strip=True))
                except ValueError:
                    pass

            volume_elem = item.find("span", {"data-ftid": "short-review-item__volume"})
            if volume_elem:
                try:
                    review_data["car_engine_volume"] = float(
                        volume_elem.get_text(strip=True)
                    )
                except ValueError:
                    pass

            # –ü–ª—é—Å—ã
            positive_elem = item.find(
                "div", {"data-ftid": "short-review-content__positive"}
            )
            if positive_elem:
                review_data["positive_text"] = positive_elem.get_text(strip=True)

            # –ú–∏–Ω—É—Å—ã
            negative_elem = item.find(
                "div", {"data-ftid": "short-review-content__negative"}
            )
            if negative_elem:
                review_data["negative_text"] = negative_elem.get_text(strip=True)

            # –ü–æ–ª–æ–º–∫–∏
            breakages_elem = item.find(
                "div", {"data-ftid": "short-review-content__breakages"}
            )
            if breakages_elem:
                review_data["breakages_text"] = breakages_elem.get_text(strip=True)

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            photos = item.find_all("img", class_="css-1e2elm8")
            review_data["photos_count"] = len(photos) if photos else 0

            return review_data if review_data else None

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ—Ç–∑—ã–≤–∞: {e}")
            return None

    def _extract_author_info(self, item) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–≤—Ç–æ—Ä–µ"""
        author_info = {}

        # –ü–æ–∏—Å–∫ –∏–º–µ–Ω–∏ –∞–≤—Ç–æ—Ä–∞
        author_elem = item.find("span", class_="css-1u4ddp")
        if author_elem:
            author_info["author_name"] = author_elem.get_text(strip=True)

        # –î–∞—Ç–∞ –æ—Ç–∑—ã–≤–∞
        date_elem = item.find("time")
        if date_elem:
            author_info["review_date"] = date_elem.get(
                "datetime"
            ) or date_elem.get_text(strip=True)

        # –ì–æ—Ä–æ–¥ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö)
        city_selectors = [
            {"data-ftid": "review-city"},
            {"class": "css-city"},
        ]

        for selector in city_selectors:
            city_elem = item.find("span", selector)
            if city_elem:
                author_info["author_city"] = city_elem.get_text(strip=True)
                break

        return author_info

    def _extract_car_info(self, item) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∞–≤—Ç–æ–º–æ–±–∏–ª—è"""
        car_info = {}

        # –ü–æ–∏—Å–∫ –±–ª–æ–∫–∞ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
        specs_text = item.get_text()

        # –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞
        year_match = re.search(r"(\d{4})\s*–≥–æ–¥", specs_text)
        if year_match:
            try:
                car_info["car_year"] = int(year_match.group(1))
            except ValueError:
                pass

        # –û–±—ä–µ–º –¥–≤–∏–≥–∞—Ç–µ–ª—è
        volume_match = re.search(r"(\d+\.?\d*)\s*–ª", specs_text)
        if volume_match:
            try:
                car_info["car_engine_volume"] = float(volume_match.group(1))
            except ValueError:
                pass

        # –¢–∏–ø —Ç–æ–ø–ª–∏–≤–∞
        fuel_types = ["–±–µ–Ω–∑–∏–Ω", "–¥–∏–∑–µ–ª—å", "–≥–∏–±—Ä–∏–¥", "—ç–ª–µ–∫—Ç—Ä–æ"]
        for fuel_type in fuel_types:
            if fuel_type in specs_text.lower():
                car_info["car_fuel_type"] = fuel_type
                break

        # –ö–æ—Ä–æ–±–∫–∞ –ø–µ—Ä–µ–¥–∞—á
        if "–∞–≤—Ç–æ–º–∞—Ç" in specs_text.lower():
            car_info["car_transmission"] = "–∞–≤—Ç–æ–º–∞—Ç"
        elif "–º–µ—Ö–∞–Ω–∏–∫–∞" in specs_text.lower():
            car_info["car_transmission"] = "–º–µ—Ö–∞–Ω–∏–∫–∞"

        # –ü—Ä–∏–≤–æ–¥
        if "–ø–µ—Ä–µ–¥–Ω–∏–π" in specs_text.lower():
            car_info["car_drive_type"] = "–ø–µ—Ä–µ–¥–Ω–∏–π"
        elif "–∑–∞–¥–Ω–∏–π" in specs_text.lower():
            car_info["car_drive_type"] = "–∑–∞–¥–Ω–∏–π"
        elif "–ø–æ–ª–Ω—ã–π" in specs_text.lower():
            car_info["car_drive_type"] = "–ø–æ–ª–Ω—ã–π"

        return car_info

    def _extract_ratings(self, item) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫"""
        ratings = {}

        # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å –æ—Ü–µ–Ω–∫–∞–º–∏
        rating_elements = item.find_all("div", class_=re.compile(r"rating"))

        for elem in rating_elements:
            text = elem.get_text(strip=True)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏
            rating_match = re.search(r"(\d+\.?\d*)", text)
            if rating_match:
                try:
                    rating_value = float(rating_match.group(1))
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—Ü–µ–Ω–∫–∏ –ø–æ —Ç–µ–∫—Å—Ç—É
                    text_lower = text.lower()
                    if "–æ–±—â–∞—è" in text_lower or "–æ–±—â–∏–π" in text_lower:
                        ratings["overall_rating"] = rating_value
                    elif "–∫–æ–º—Ñ–æ—Ä—Ç" in text_lower:
                        ratings["comfort_rating"] = rating_value
                    elif "–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å" in text_lower:
                        ratings["reliability_rating"] = rating_value
                    elif "—Ä–∞—Å—Ö–æ–¥" in text_lower:
                        ratings["fuel_consumption_rating"] = rating_value
                    elif "–≤–æ–∂–¥–µ–Ω–∏–µ" in text_lower:
                        ratings["driving_rating"] = rating_value
                    elif "–≤–Ω–µ—à–Ω–∏–π" in text_lower:
                        ratings["appearance_rating"] = rating_value
                except ValueError:
                    pass

        return ratings

    def save_reviews_to_db(
        self,
        brand_url_name: str,
        model_url_name: str,
        long_reviews: List[Dict],
        short_reviews: List[Dict],
    ) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –±–∞–∑—ã
            brand = self.db_manager.get_brand_by_url_name(brand_url_name)
            if not brand:
                self.logger.error(f"–ë—Ä–µ–Ω–¥ {brand_url_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ")
                return False

            model = self.db_manager.get_model_by_url_name(brand["id"], model_url_name)
            if not model:
                self.logger.error(
                    f"–ú–æ–¥–µ–ª—å {model_url_name} "
                    f"–Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–ª—è –±—Ä–µ–Ω–¥–∞ {brand_url_name}"
                )
                return False

            model_id = model["id"]
            saved_count = 0

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
            for review in long_reviews:
                review_id = self.db_manager.add_review(
                    model_id=model_id, review_type="long", **review
                )
                if review_id:
                    saved_count += 1

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–∑—ã–≤—ã
            for review in short_reviews:
                review_id = self.db_manager.add_review(
                    model_id=model_id, review_type="short", **review
                )
                if review_id:
                    saved_count += 1

            self.logger.info(
                f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –æ—Ç–∑—ã–≤–æ–≤ " f"–¥–ª—è –º–æ–¥–µ–ª–∏ {model['name']}"
            )

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏
            self.db_manager.update_reviews_count()

            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤: {e}")
            return False

    def parse_model_reviews(
        self,
        brand_url_name: str,
        model_url_name: str,
        max_pages_long: int = 5,
        max_pages_short: int = 10,
    ) -> bool:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ –º–æ–¥–µ–ª–∏ (–¥–ª–∏–Ω–Ω—ã–µ + –∫–æ—Ä–æ—Ç–∫–∏–µ)"""
        self.logger.info(
            f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è {brand_url_name}/{model_url_name}"
        )

        # –ü–∞—Ä—Å–∏–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
        long_reviews = self.parse_long_reviews(
            brand_url_name, model_url_name, max_pages_long
        )

        # –ü–∞—Ä—Å–∏–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–∑—ã–≤—ã
        short_reviews = self.parse_short_reviews(
            brand_url_name, model_url_name, max_pages_short
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        if long_reviews or short_reviews:
            return self.save_reviews_to_db(
                brand_url_name, model_url_name, long_reviews, short_reviews
            )
        else:
            self.logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return False


if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞
    parser = DromReviewsParser(delay=1.0)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    if not parser.db_manager.create_database():
        print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö!")
        exit(1)

    # –ü—Ä–∏–º–µ—Ä –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è Toyota 4Runner
    success = parser.parse_model_reviews(
        brand_url_name="toyota",
        model_url_name="4runner",
        max_pages_long=2,
        max_pages_short=3,
    )

    if success:
        print("\nüéâ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = parser.db_manager.get_statistics()
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:")
        print(f"   üè¢ –ë—Ä–µ–Ω–¥–æ–≤: {stats.get('brands_count', 0)}")
        print(f"   üöó –ú–æ–¥–µ–ª–µ–π: {stats.get('models_count', 0)}")
        print(f"   üìù –û—Ç–∑—ã–≤–æ–≤ –≤—Å–µ–≥–æ: {stats.get('total_reviews', 0)}")
        print(f"   üìÑ –î–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {stats.get('long_reviews', 0)}")
        print(f"   üìã –ö–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤: {stats.get('short_reviews', 0)}")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–æ–≤!")
