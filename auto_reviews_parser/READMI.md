# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞ –æ—Ç–∑—ã–≤–æ–≤

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ä–µ–¥—ã
```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥—ã
python -m venv parser_env
source parser_env/bin/activate  # Linux/Mac

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install botasaurus pandas matplotlib seaborn
```

### 2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
```bash
mkdir auto_reviews_project
cd auto_reviews_project

# –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª—ã:
# - auto_reviews_parser.py
# - data_analyzer.py
```

## –°—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
```bash
# 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
python auto_reviews_parser.py init

# 2. –¢–µ—Å—Ç–æ–≤–∞—è —Å–µ—Å—Å–∏—è (2-3 –∏—Å—Ç–æ—á–Ω–∏–∫–∞)
python auto_reviews_parser.py parse --sources 3

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
python auto_reviews_parser.py status
python data_analyzer.py stats
```

### üìä –ú–µ—Å—è—á–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
```bash
# –©–∞–¥—è—â–∏–π —Ä–µ–∂–∏–º: 2 —Å–µ—Å—Å–∏–∏ –≤ –¥–µ–Ω—å –ø–æ 5 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
nohup python auto_reviews_parser.py continuous --sessions 2 --sources 5 > parser.log 2>&1 &

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞
tail -f parser.log
python auto_reviews_parser.py status
```

### ‚ö° –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã–π —Å–±–æ—Ä (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –Ω–∞–ø–æ–ª–Ω–µ–Ω–∏—è)
```bash
# 4 —Å–µ—Å—Å–∏–∏ –≤ –¥–µ–Ω—å –ø–æ 10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
python auto_reviews_parser.py continuous --sessions 4 --sources 10
```

### üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `Config.TARGET_BRANDS` –≤ —Ñ–∞–π–ª–µ `auto_reviews_parser.py`:

```python
# –ü—Ä–∏–º–µ—Ä: —Ç–æ–ª—å–∫–æ –ø—Ä–µ–º–∏—É–º –±—Ä–µ–Ω–¥—ã
TARGET_BRANDS = {
    'bmw': ['3-series', '5-series', 'x3', 'x5', 'x1'],
    'mercedes-benz': ['c-class', 'e-class', 's-class', 'glc', 'gle'],
    'audi': ['a3', 'a4', 'a6', 'q3', 'q5', 'q7'],
    'lexus': ['rx', 'es', 'is', 'nx', 'gx']
}

# –ò–ª–∏ –º–∞—Å—Å–æ–≤—ã–π —Ä—ã–Ω–æ–∫
TARGET_BRANDS = {
    'toyota': ['camry', 'corolla', 'rav4', 'highlander'],
    'volkswagen': ['polo', 'golf', 'passat', 'tiguan'],
    'hyundai': ['solaris', 'elantra', 'tucson', 'santa-fe'],
    'kia': ['rio', 'cerato', 'sportage', 'sorento']
}
```

## –ê–Ω–∞–ª–∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### üìà –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
```bash
python data_analyzer.py stats
```

### üìã –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç (HTML)
```bash
python data_analyzer.py report
# –°–æ–∑–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª analysis_report_YYYYMMDD_HHMMSS.html
```

### üîç –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞
```bash
python data_analyzer.py brand --brand toyota
python data_analyzer.py brand --brand bmw
```

### üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
```bash
# JSON –¥–ª—è API/–≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
python data_analyzer.py export --output analytics_data.json

# Excel –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
python auto_reviews_parser.py export --format xlsx
```

### üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–æ–∫—É–ø–∫–µ
```bash
python data_analyzer.py recommendations
```

## –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### Systemd Service (Linux)

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `/etc/systemd/system/auto-reviews-parser.service`:

```ini
[Unit]
Description=Auto Reviews Parser
After=network.target
StartLimitIntervalSec=0

[Service]
Type=simple
User=parser
Group=parser
WorkingDirectory=/home/parser/auto_reviews_project
Environment=PATH=/home/parser/auto_reviews_project/parser_env/bin
ExecStart=/home/parser/auto_reviews_project/parser_env/bin/python auto_reviews_parser.py continuous --sessions 2 --sources 5
Restart=always
RestartSec=30
StandardOutput=append:/var/log/auto-parser.log
StandardError=append:/var/log/auto-parser-error.log

[Install]
WantedBy=multi-user.target
```

–ê–∫—Ç–∏–≤–∞—Ü–∏—è:
```bash
sudo systemctl enable auto-reviews-parser
sudo systemctl start auto-reviews-parser
sudo systemctl status auto-reviews-parser
```

### Cron –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤

```bash
# –û—Ç–∫—Ä—ã—Ç—å crontab
crontab -e

# –î–æ–±–∞–≤–∏—Ç—å –∑–∞–¥–∞—á–∏:
# –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç –≤ 9:00
0 9 * * * cd /path/to/project && python data_analyzer.py report

# –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö (–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ 18:00)
0 18 * * 0 cd /path/to/project && python auto_reviews_parser.py export --format xlsx

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ –∫–∞–∂–¥—ã–π —á–∞—Å
0 * * * * df -h | awk '$5 > 85 {print "Disk usage critical: " $5 " on " $1}' | mail -s "Disk Alert" admin@example.com
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–ª–µ—Ä—Ç—ã

```bash
#!/bin/bash
# –§–∞–π–ª: check_parser_health.sh

LOG_FILE="/var/log/auto-parser.log"
RECENT_ENTRIES=$(tail -100 "$LOG_FILE" | grep "$(date '+%Y-%m-%d')" | wc -l)

if [ $RECENT_ENTRIES -lt 5 ]; then
    echo "WARNING: Parser seems inactive (only $RECENT_ENTRIES entries today)"
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—à–∏–±–æ–∫
ERROR_COUNT=$(tail -1000 "$LOG_FILE" | grep -i error | wc -l)
if [ $ERROR_COUNT -gt 10 ]; then
    echo "WARNING: High error count ($ERROR_COUNT errors in last 1000 entries)"
    exit 1
fi

echo "Parser is healthy: $RECENT_ENTRIES entries today, $ERROR_COUNT recent errors"
```

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã

### –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
```python
# –ü—Ä–∏–º–µ—Ä: –ø–æ–∏—Å–∫ –≤—Å–µ—Ö –æ—Ç–∑—ã–≤–æ–≤ Toyota Camry
import sqlite3
import pandas as pd

conn = sqlite3.connect('auto_reviews.db')

camry_reviews = pd.read_sql_query("""
    SELECT title, rating, content, author, year, mileage, publish_date, url
    FROM reviews 
    WHERE brand = 'toyota' AND model = 'camry'
    ORDER BY publish_date DESC
""", conn)

print(f"–ù–∞–π–¥–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤ Toyota Camry: {len(camry_reviews)}")
print(f"–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {camry_reviews['rating'].mean():.2f}")

# –û—Ç–∑—ã–≤—ã –ø–æ –≥–æ–¥–∞–º –≤—ã–ø—É—Å–∫–∞
year_stats = camry_reviews.groupby('year').agg({
    'rating': 'mean',
    'title': 'count'
}).round(2)

print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥–æ–¥–∞–º:")
print(year_stats)
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–æ–≤
```python
import matplotlib.pyplot as plt

# –°—Ä–µ–¥–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∏ —Ç–æ–ø-10 –±—Ä–µ–Ω–¥–æ–≤
brand_ratings = pd.read_sql_query("""
    SELECT brand, AVG(rating) as avg_rating, COUNT(*) as review_count
    FROM reviews 
    WHERE rating IS NOT NULL 
    GROUP BY brand 
    HAVING review_count >= 20
    ORDER BY avg_rating DESC 
    LIMIT 10
""", conn)

plt.figure(figsize=(12, 6))
plt.bar(brand_ratings['brand'], brand_ratings['avg_rating'])
plt.title('–°—Ä–µ–¥–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∏ –±—Ä–µ–Ω–¥–æ–≤ (–ø–æ –æ—Ç–∑—ã–≤–∞–º –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤)')
plt.ylabel('–†–µ–π—Ç–∏–Ω–≥')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('brand_ratings.png', dpi=300)
plt.show()
```

### –ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
```python
# –ú–æ–¥–µ–ª–∏ —Å –Ω–∏–∑–∫–∏–º–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏ –∏ —á–∞—Å—Ç—ã–º–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è–º–∏ –ø—Ä–æ–±–ª–µ–º
problematic_models = pd.read_sql_query("""
    SELECT brand, model, AVG(rating) as avg_rating, COUNT(*) as review_count,
           AVG(LENGTH(cons)) as avg_cons_length
    FROM reviews 
    WHERE rating IS NOT NULL AND rating < 3.0
    GROUP BY brand, model 
    HAVING review_count >= 5
    ORDER BY avg_rating ASC, avg_cons_length DESC
""", conn)

print("–ú–æ–¥–µ–ª–∏ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤:")
for _, row in problematic_models.head(10).iterrows():
    print(f"{row['brand']} {row['model']}: {row['avg_rating']:.1f}‚òÖ ({int(row['review_count'])} –æ—Ç–∑—ã–≤–æ–≤)")
```

## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–ª–∞–±—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
```python
# –í auto_reviews_parser.py –∏–∑–º–µ–Ω–∏—Ç–µ Config:
class Config:
    MIN_DELAY = 10      # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏
    MAX_DELAY = 25
    PAGES_PER_SESSION = 20  # –ú–µ–Ω—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü –∑–∞ —Ä–∞–∑
    MAX_REVIEWS_PER_MODEL = 500  # –ú–µ–Ω—å—à–∏–π –ª–∏–º–∏—Ç
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –º–æ—â–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
```python
class Config:
    MIN_DELAY = 3       # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    MAX_DELAY = 8
    PAGES_PER_SESSION = 100
    MAX_REVIEWS_PER_MODEL = 2000
```

### –û—á–∏—Å—Ç–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ë–î
```bash
#!/bin/bash
# –§–∞–π–ª: optimize_db.sh

echo "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö..."

# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∑–∞–ø–∏—Å–µ–π
sqlite3 auto_reviews.db "
DELETE FROM reviews 
WHERE id NOT IN (
    SELECT MIN(id) 
    FROM reviews 
    GROUP BY content_hash
);"

# –°–∂–∞—Ç–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
sqlite3 auto_reviews.db "VACUUM;"

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
sqlite3 auto_reviews.db "ANALYZE;"

echo "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞"
```

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏

### REST API –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º
```python
# –ü—Ä–æ—Å—Ç–æ–π Flask API
from flask import Flask, jsonify
import sqlite3

app = Flask(__name__)

@app.route('/api/stats')
def get_stats():
    conn = sqlite3.connect('auto_reviews.db')
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM reviews")
    total = cursor.fetchone()[0]
    
    cursor.execute("SELECT brand, COUNT(*) FROM reviews GROUP BY brand")
    by_brand = dict(cursor.fetchall())
    
    conn.close()
    
    return jsonify({
        'total_reviews': total,
        'by_brand': by_brand
    })

@app.route('/api/brand/<brand>')
def get_brand_data(brand):
    conn = sqlite3.connect('auto_reviews.db')
    
    reviews = pd.read_sql_query(
        "SELECT * FROM reviews WHERE brand = ? LIMIT 100", 
        conn, params=[brand]
    )
    
    conn.close()
    
    return jsonify(reviews.to_dict('records'))

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

### Webhook —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
```python
import requests

def send_webhook_notification(message):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Slack/Discord/Telegram"""
    webhook_url = "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
    
    payload = {
        "text": f"üöó Auto Parser: {message}",
        "username": "Auto Reviews Bot"
    }
    
    try:
        requests.post(webhook_url, json=payload)
    except Exception as e:
        print(f"Failed to send webhook: {e}")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –ø–∞—Ä—Å–µ—Ä–µ
def run_parsing_session(self, max_sources: int = 10):
    # ... –∫–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ ...
    
    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Å–µ—Å—Å–∏–∏
    send_webhook_notification(
        f"–°–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {sources_processed} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, "
        f"—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {total_reviews_saved} –æ—Ç–∑—ã–≤–æ–≤"
    )
```

## –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

### 1. –ü–∞—Ä—Å–µ—Ä –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
tail -100 logs/parser_$(date +%Y%m%d).log

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º
python auto_reviews_parser.py parse --sources 5
```

### 2. –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ 403/429
```python
# –£–≤–µ–ª–∏—á–∏—Ç—å –∑–∞–¥–µ—Ä–∂–∫–∏ –≤ Config
MIN_DELAY = 15
MAX_DELAY = 30
ERROR_DELAY = 60
```

### 3. –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã
lsof auto_reviews.db

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å
sqlite3 auto_reviews.db ".timeout 30000; SELECT 1;"
```

### 4. –ù–µ—Ö–≤–∞—Ç–∫–∞ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
```bash
# –û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤
find logs/ -name "*.log" -mtime +7 -delete

# –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞ botasaurus
rm -rf cache/

# –°–∂–∞—Ç–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
sqlite3 auto_reviews.db "VACUUM;"
```

–≠—Ç–æ—Ç –ø–∞—Ä—Å–µ—Ä —Å–æ–∑–¥–∞–Ω –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã. –ü—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –æ–Ω –±—É–¥–µ—Ç —Å–æ–±–∏—Ä–∞—Ç—å —Ç—ã—Å—è—á–∏ –æ—Ç–∑—ã–≤–æ–≤ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ –±–µ–∑ –≤–∞—à–µ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞.