#!/usr/bin/env python3
"""
üöÄ –ö–ê–¢–ê–õ–û–ñ–ù–´–ô –ü–ê–†–°–ï–† –û–¢–ó–´–í–û–í DROM.RU (–≤–µ—Ä—Å–∏—è 2.0)

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏:
- brands: –∫–∞—Ç–∞–ª–æ–≥ –±—Ä–µ–Ω–¥–æ–≤
- models: –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±—Ä–µ–Ω–¥–∞
- reviews: –æ—Ç–∑—ã–≤—ã –ø–æ –º–æ–¥–µ–ª—è–º

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –†–∞–±–æ—Ç–∞–µ—Ç —Å –∫–∞—Ç–∞–ª–æ–≥–æ–º –±—Ä–µ–Ω–¥–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –±—Ä–µ–Ω–¥–∞–º –∏ –º–æ–¥–µ–ª—è–º
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å –Ω–µ–ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–µ—Ç—Ä–∏–∫–∏
"""

import logging
import time
import re
import sqlite3
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup

from database_schema import DatabaseManager


@dataclass
class ReviewData:
    """–î–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤–∞"""

    review_id: str
    url: str
    title: str = ""
    content: str = ""
    author: str = ""
    publish_date: str = ""
    rating: float = 0.0
    pros: str = ""
    cons: str = ""
    general_impression: str = ""
    experience_period: str = ""
    car_year: int = 0
    car_modification: str = ""


@dataclass
class ParseResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞"""

    brand_slug: str
    brand_name: str
    processed_models: int
    total_reviews: int
    new_reviews: int
    skipped_reviews: int
    error_reviews: int
    duration_seconds: float
    errors: List[str]


class CatalogBasedParser:
    """–ü–∞—Ä—Å–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –±—Ä–µ–Ω–¥–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(
        self,
        db_path: str = "auto_reviews.db",
        browser_path: str = "/home/analityk/–î–æ–∫—É–º–µ–Ω—Ç—ã/projects/parser_project/chrome-linux/chrome",
    ):
        self.db_manager = DatabaseManager(db_path)
        self.browser_path = browser_path
        self.base_url = "https://www.drom.ru/reviews/"

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)

        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(log_dir / "catalog_parser_v2.log"),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger(__name__)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        self.check_database()

    def check_database(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        if not Path(self.db_manager.db_path).exists():
            self.logger.error(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.db_manager.db_path}")
            self.logger.info("üîß –°–æ–∑–¥–∞–π—Ç–µ –µ–µ —Å–Ω–∞—á–∞–ª–∞ —Å –ø–æ–º–æ—â—å—é database_schema.py")
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –±—Ä–µ–Ω–¥–æ–≤
        brands = self.db_manager.get_all_brands()
        if not brands:
            self.logger.error("‚ùå –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –±—Ä–µ–Ω–¥–æ–≤!")
            self.logger.info("üîß –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –∫–∞—Ç–∞–ª–æ–≥ —Å –ø–æ–º–æ—â—å—é catalog_initializer.py")
            return False

        self.logger.info(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≥–æ—Ç–æ–≤–∞: {len(brands)} –±—Ä–µ–Ω–¥–æ–≤")
        return True

    def extract_review_urls_from_model_page(
        self, brand_slug: str, model_slug: str, max_pages: int = 5
    ) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL –æ—Ç–∑—ã–≤–æ–≤ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–æ–¥–µ–ª–∏"""
        review_urls = []

        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(
                    executable_path=self.browser_path,
                    headless=True,
                    args=["--no-sandbox", "--disable-dev-shm-usage"],
                )

                page = browser.new_page()
                model_url = f"{self.base_url}{brand_slug}/{model_slug}/"

                self.logger.info(f"–ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–∑—ã–≤—ã: {model_url}")

                for page_num in range(1, max_pages + 1):
                    try:
                        if page_num == 1:
                            page.goto(model_url, wait_until="networkidle")
                        else:
                            page_url = f"{model_url}?page={page_num}"
                            page.goto(page_url, wait_until="networkidle")

                        time.sleep(2)

                        # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ—Ç–∑—ã–≤—ã
                        content = page.content()
                        soup = BeautifulSoup(content, "html.parser")

                        # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–∑—ã–≤–æ–≤
                        review_selectors = [
                            f'a[href*="/reviews/{brand_slug}/{model_slug}/"]',
                            ".review-item a",
                            ".review-link",
                            'a[href*="/reviews/"]',
                        ]

                        for selector in review_selectors:
                            links = soup.select(selector)

                            for link in links:
                                href = link.get("href", "")

                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ç–∑—ã–≤
                                pattern = rf"/reviews/{re.escape(brand_slug)}/{re.escape(model_slug)}/(\d+)/?"
                                match = re.search(pattern, href)

                                if match:
                                    full_url = (
                                        href
                                        if href.startswith("http")
                                        else f"https://www.drom.ru{href}"
                                    )
                                    review_urls.append(full_url)

                            if review_urls:
                                break

                        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –æ—Ç–∑—ã–≤—ã, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                        if not review_urls:
                            break

                    except Exception as e:
                        self.logger.warning(f"–û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {e}")
                        continue

                browser.close()

        except Exception as e:
            self.logger.error(
                f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è {brand_slug}/{model_slug}: {e}"
            )

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_urls = list(set(review_urls))
        self.logger.info(
            f"–ù–∞–π–¥–µ–Ω–æ {len(unique_urls)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è {model_slug}"
        )

        return unique_urls

    def parse_review_page(self, review_url: str) -> Optional[ReviewData]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–∑—ã–≤–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –æ—Ç–∑—ã–≤–∞ –∏–∑ URL
            review_id_match = re.search(r"/(\d+)/?$", review_url)
            if not review_id_match:
                return None

            review_id = review_id_match.group(1)

            with sync_playwright() as p:
                browser = p.chromium.launch(
                    executable_path=self.browser_path,
                    headless=True,
                    args=["--no-sandbox", "--disable-dev-shm-usage"],
                )

                page = browser.new_page()
                page.goto(review_url, wait_until="networkidle")
                time.sleep(2)

                content = page.content()
                soup = BeautifulSoup(content, "html.parser")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤–∞
                review_data = ReviewData(review_id=review_id, url=review_url)

                # –ó–∞–≥–æ–ª–æ–≤–æ–∫
                title_elem = soup.find("h1") or soup.find(".review-title")
                if title_elem:
                    review_data.title = title_elem.get_text(strip=True)

                # –ê–≤—Ç–æ—Ä
                author_elem = soup.find(".review-author") or soup.find(".author")
                if author_elem:
                    review_data.author = author_elem.get_text(strip=True)

                # –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–∞
                content_elem = soup.find(".review-content") or soup.find(".review-text")
                if content_elem:
                    review_data.content = content_elem.get_text(strip=True)

                # –ü–ª—é—Å—ã
                pros_elem = soup.find(".review-pros") or soup.find(".pros")
                if pros_elem:
                    review_data.pros = pros_elem.get_text(strip=True)

                # –ú–∏–Ω—É—Å—ã
                cons_elem = soup.find(".review-cons") or soup.find(".cons")
                if cons_elem:
                    review_data.cons = cons_elem.get_text(strip=True)

                # –û–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ
                impression_elem = soup.find(".review-impression") or soup.find(
                    ".general-impression"
                )
                if impression_elem:
                    review_data.general_impression = impression_elem.get_text(
                        strip=True
                    )

                browser.close()

                return review_data

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–∞ {review_url}: {e}")
            return None

    def save_review_to_database(
        self, review_data: ReviewData, brand_slug: str, model_slug: str
    ) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()

            # –ü–æ–ª—É—á–∞–µ–º ID –±—Ä–µ–Ω–¥–∞ –∏ –º–æ–¥–µ–ª–∏
            cursor.execute(
                """
                SELECT b.id, m.id 
                FROM brands b
                JOIN models m ON m.brand_id = b.id
                WHERE b.slug = ? AND m.slug = ?
            """,
                (brand_slug, model_slug),
            )

            result = cursor.fetchone()
            if not result:
                self.logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω –±—Ä–µ–Ω–¥/–º–æ–¥–µ–ª—å: {brand_slug}/{model_slug}")
                conn.close()
                return False

            brand_id, model_id = result

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π –æ—Ç–∑—ã–≤
            cursor.execute(
                "SELECT id FROM reviews WHERE review_id = ?", (review_data.review_id,)
            )
            existing = cursor.fetchone()

            if existing:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ—Ç–∑—ã–≤
                cursor.execute(
                    """
                    UPDATE reviews SET
                        title = ?, content = ?, author = ?, publish_date = ?,
                        rating = ?, pros = ?, cons = ?, general_impression = ?,
                        experience_period = ?, car_year = ?, car_modification = ?,
                        is_complete = ?, parse_attempts = parse_attempts + 1
                    WHERE review_id = ?
                """,
                    (
                        review_data.title,
                        review_data.content,
                        review_data.author,
                        review_data.publish_date,
                        review_data.rating,
                        review_data.pros,
                        review_data.cons,
                        review_data.general_impression,
                        review_data.experience_period,
                        review_data.car_year,
                        review_data.car_modification,
                        1,
                        review_data.review_id,
                    ),
                )
                self.logger.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω –æ—Ç–∑—ã–≤: {review_data.review_id}")
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ—Ç–∑—ã–≤
                cursor.execute(
                    """
                    INSERT INTO reviews (
                        brand_id, model_id, review_id, url, title, content, author,
                        publish_date, rating, pros, cons, general_impression,
                        experience_period, car_year, car_modification, is_complete, parse_attempts
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        brand_id,
                        model_id,
                        review_data.review_id,
                        review_data.url,
                        review_data.title,
                        review_data.content,
                        review_data.author,
                        review_data.publish_date,
                        review_data.rating,
                        review_data.pros,
                        review_data.cons,
                        review_data.general_impression,
                        review_data.experience_period,
                        review_data.car_year,
                        review_data.car_modification,
                        1,
                        1,
                    ),
                )
                self.logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –æ—Ç–∑—ã–≤: {review_data.review_id}")

            conn.commit()
            conn.close()
            return True

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–∑—ã–≤–∞: {e}")
            return False

    def parse_brand_models(
        self, brand_slug: str, max_models: int = None, max_reviews: int = 10
    ) -> ParseResult:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –±—Ä–µ–Ω–¥–∞"""
        start_time = time.time()

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—Ä–µ–Ω–¥–µ
        brands = [
            b for b in self.db_manager.get_all_brands() if b["slug"] == brand_slug
        ]
        if not brands:
            return ParseResult(
                brand_slug=brand_slug,
                brand_name="Unknown",
                processed_models=0,
                total_reviews=0,
                new_reviews=0,
                skipped_reviews=0,
                error_reviews=0,
                duration_seconds=0,
                errors=[f"–ë—Ä–µ–Ω–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω: {brand_slug}"],
            )

        brand_name = brands[0]["name"]

        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –±—Ä–µ–Ω–¥–∞
        models = self.db_manager.get_brand_models(brand_slug)
        if max_models:
            models = models[:max_models]

        self.logger.info(f"üöó –ü–∞—Ä—Å–∏–Ω–≥ –±—Ä–µ–Ω–¥–∞ {brand_name}: {len(models)} –º–æ–¥–µ–ª–µ–π")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        processed_models = 0
        total_reviews = 0
        new_reviews = 0
        skipped_reviews = 0
        error_reviews = 0
        errors = []

        for i, model in enumerate(models, 1):
            model_slug = model["slug"]
            model_name = model["name"]

            self.logger.info(f"[{i}/{len(models)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å: {model_name}")

            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
                review_urls = self.extract_review_urls_from_model_page(
                    brand_slug, model_slug
                )

                if max_reviews:
                    review_urls = review_urls[:max_reviews]

                total_reviews += len(review_urls)

                # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π –æ—Ç–∑—ã–≤
                for j, review_url in enumerate(review_urls, 1):
                    try:
                        self.logger.info(
                            f"  [{j}/{len(review_urls)}] –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–∞: {review_url}"
                        )

                        review_data = self.parse_review_page(review_url)
                        if review_data:
                            if self.save_review_to_database(
                                review_data, brand_slug, model_slug
                            ):
                                new_reviews += 1
                            else:
                                error_reviews += 1
                        else:
                            error_reviews += 1

                        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –æ—Ç–∑—ã–≤–∞–º–∏
                        time.sleep(1)

                    except Exception as e:
                        error_msg = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–∞ {review_url}: {e}"
                        self.logger.error(error_msg)
                        errors.append(error_msg)
                        error_reviews += 1

                processed_models += 1

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
                if i < len(models):
                    time.sleep(2)

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}"
                self.logger.error(error_msg)
                errors.append(error_msg)

        duration = time.time() - start_time

        return ParseResult(
            brand_slug=brand_slug,
            brand_name=brand_name,
            processed_models=processed_models,
            total_reviews=total_reviews,
            new_reviews=new_reviews,
            skipped_reviews=skipped_reviews,
            error_reviews=error_reviews,
            duration_seconds=duration,
            errors=errors,
        )

    def get_parsing_statistics(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        return self.db_manager.get_database_stats()


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="–ö–∞—Ç–∞–ª–æ–∂–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –æ—Ç–∑—ã–≤–æ–≤ Drom.ru v2.0"
    )
    parser.add_argument("--brand", type=str, help="Slug –±—Ä–µ–Ω–¥–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
    parser.add_argument(
        "--max-models", type=int, default=5, help="–ú–∞–∫—Å–∏–º—É–º –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    )
    parser.add_argument(
        "--max-reviews", type=int, default=5, help="–ú–∞–∫—Å–∏–º—É–º –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –º–æ–¥–µ–ª—å"
    )
    parser.add_argument(
        "--list-brands", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –±—Ä–µ–Ω–¥—ã"
    )

    args = parser.parse_args()

    print("üöÄ –ö–ê–¢–ê–õ–û–ñ–ù–´–ô –ü–ê–†–°–ï–† –û–¢–ó–´–í–û–í DROM.RU v2.0")
    print("=" * 50)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
    catalog_parser = CatalogBasedParser()

    if args.list_brands:
        brands = catalog_parser.db_manager.get_all_brands()
        print(f"\nüìã –î–û–°–¢–£–ü–ù–´–ï –ë–†–ï–ù–î–´ ({len(brands)}):")
        for brand in brands:
            print(
                f"- {brand['name']} ({brand['slug']}) - {brand['review_count']} –æ—Ç–∑—ã–≤–æ–≤"
            )
        return 0

    if not args.brand:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ –±—Ä–µ–Ω–¥ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: --brand SLUG")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --list-brands –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤")
        return 1

    # –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞
    print(f"\nüéØ –ü–ê–†–°–ò–ù–ì –ë–†–ï–ù–î–ê: {args.brand}")
    print(f"–ú–∞–∫—Å–∏–º—É–º –º–æ–¥–µ–ª–µ–π: {args.max_models}")
    print(f"–ú–∞–∫—Å–∏–º—É–º –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –º–æ–¥–µ–ª—å: {args.max_reviews}")

    result = catalog_parser.parse_brand_models(
        brand_slug=args.brand, max_models=args.max_models, max_reviews=args.max_reviews
    )

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–ê–†–°–ò–ù–ì–ê:")
    print(f"–ë—Ä–µ–Ω–¥: {result.brand_name} ({result.brand_slug})")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {result.processed_models}")
    print(f"–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {result.total_reviews}")
    print(f"–ù–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {result.new_reviews}")
    print(f"–û—à–∏–±–æ–∫: {result.error_reviews}")
    print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.duration_seconds:.2f} —Å–µ–∫")

    if result.errors:
        print(f"\n‚ö†Ô∏è –û–®–ò–ë–ö–ò ({len(result.errors)}):")
        for error in result.errors[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
            print(f"- {error}")

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = catalog_parser.get_parsing_statistics()
    print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
    print(f"–ë—Ä–µ–Ω–¥–æ–≤: {stats.get('brands', 0)}")
    print(f"–ú–æ–¥–µ–ª–µ–π: {stats.get('models', 0)}")
    print(f"–û—Ç–∑—ã–≤–æ–≤: {stats.get('reviews', 0)}")
    print(f"–ü–æ–ª–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {stats.get('complete_reviews', 0)}")
    print(f"–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏: {stats.get('completion_rate', 0)}%")

    return 0


if __name__ == "__main__":
    exit(main())
