#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ —Å –ø–æ–ª–Ω—ã–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
"""

import sys
import os
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(project_root, 'src'))

from auto_reviews_parser.parsers.simple_master_parser import MasterDromParser, ModelInfo

def test_comprehensive_parsing():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤"""
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = MasterDromParser()
    
    # –¢–µ—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å (Toyota 4Runner)
    test_model = ModelInfo(
        name="4Runner",
        brand="Toyota", 
        url="https://www.drom.ru/reviews/toyota/4runner/",
        url_name="4runner"
    )
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ URL –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤
    test_urls = [
        "https://www.drom.ru/reviews/toyota/4runner/1425079/",
        "https://www.drom.ru/reviews/toyota/4runner/1384584/",
        "https://www.drom.ru/reviews/toyota/4runner/1298473/"
    ]
    
    results = []
    
    for i, url in enumerate(test_urls, 1):
        print(f"\nüìÑ –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–∞ {i}/{len(test_urls)}: {url}")
        
        try:
            # –ü–∞—Ä—Å–∏–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–∑—ã–≤–∞
            review_data = parser._parse_individual_review_page(url, test_model)
            
            if review_data:
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –æ—Ç–∑—ã–≤: {review_data.title[:80] if review_data.title else '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞'}...")
                print(f"   üìä –†–µ–π—Ç–∏–Ω–≥: {review_data.rating}")
                print(f"   üë§ –ê–≤—Ç–æ—Ä: {review_data.author}")
                print(f"   üìÖ –î–∞—Ç–∞: {review_data.date}")
                print(f"   üì∏ –§–æ—Ç–æ: {review_data.photos_count}")
                print(f"   üìÑ –ö–æ–Ω—Ç–µ–Ω—Ç: {len(review_data.content) if review_data.content else 0} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                review_dict = {
                    'review_id': review_data.review_id,
                    'brand': review_data.brand,
                    'model': review_data.model,
                    'review_type': review_data.review_type,
                    'url': review_data.url,
                    'title': review_data.title,
                    'author': review_data.author,
                    'rating': review_data.rating,
                    'content': review_data.content[:500] if review_data.content else None,  # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª—è –≤—ã–≤–æ–¥–∞
                    'date': review_data.date,
                    'photos_count': review_data.photos_count,
                    'photos': review_data.photos[:3] if review_data.photos else [],  # –ü–µ—Ä–≤—ã–µ 3 —Ñ–æ—Ç–æ
                    'parsed_at': review_data.parsed_at.isoformat() if review_data.parsed_at else None
                }
                
                results.append(review_dict)
                
            else:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–∑—ã–≤: {url}")
                
        except Exception as e:
            print(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {url}: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"data/comprehensive_long_reviews_test_{timestamp}.json"
    
    os.makedirs("data", exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'test_info': {
                'timestamp': timestamp,
                'total_urls': len(test_urls),
                'successful_parses': len(results),
                'test_model': {
                    'brand': test_model.brand,
                    'name': test_model.name,
                    'url_name': test_model.url_name
                }
            },
            'results': results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞:")
    print(f"   üéØ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ URL: {len(test_urls)}")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(results)}")
    print(f"   üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    
    if results:
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–∑—ã–≤–∞:")
        first_review = results[0]
        for key, value in first_review.items():
            if key != 'content':  # –ù–µ –≤—ã–≤–æ–¥–∏–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç
                print(f"   {key}: {value}")

if __name__ == "__main__":
    test_comprehensive_parsing()
