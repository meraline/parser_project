#!/usr/bin/env python3
"""
–°—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –æ—Ç–∑—ã–≤–æ–≤ –∏ –±–æ—Ä—Ç–∂—É—Ä–Ω–∞–ª–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å Drom.ru –∏ Drive2.ru –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
–†–∞–±–æ—Ç–∞–µ—Ç –≤ —â–∞–¥—è—â–µ–º —Ä–µ–∂–∏–º–µ –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
"""

import time
import random
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import re
import json
import logging
from urllib.parse import urljoin, urlparse
import hashlib
from pathlib import Path

from botasaurus.browser import browser, Driver
from botasaurus.request import request, Request
from botasaurus.soupify import soupify
from botasaurus import bt

from src.database.base import Database
from src.database.repositories.review_repository import ReviewRepository
from src.database.repositories.queue_repository import QueueRepository

# ==================== –ù–ê–°–¢–†–û–ô–ö–ò ====================


class Config:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""

    # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    DB_PATH = "auto_reviews.db"

    # –ó–∞–¥–µ—Ä–∂–∫–∏ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
    MIN_DELAY = 5  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    MAX_DELAY = 15  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    ERROR_DELAY = 30  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    RATE_LIMIT_DELAY = 300  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ rate limit (5 –º–∏–Ω—É—Ç)

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    MAX_RETRIES = 3  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤
    PAGES_PER_SESSION = 50  # –°—Ç—Ä–∞–Ω–∏—Ü –∑–∞ —Å–µ—Å—Å–∏—é
    MAX_REVIEWS_PER_MODEL = 1000  # –ú–∞–∫—Å–∏–º—É–º –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –º–æ–¥–µ–ª—å

    # User agents –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
    USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    ]

    # –°–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    TARGET_BRANDS = {
        "toyota": ["camry", "corolla", "rav4", "highlander", "prius", "land-cruiser"],
        "volkswagen": ["polo", "golf", "passat", "tiguan", "touareg", "jetta"],
        "nissan": ["qashqai", "x-trail", "almera", "teana", "murano", "pathfinder"],
        "hyundai": ["solaris", "elantra", "tucson", "santa-fe", "creta", "sonata"],
        "kia": ["rio", "cerato", "sportage", "sorento", "soul", "optima"],
        "mazda": ["mazda3", "mazda6", "cx-5", "cx-3", "mx-5", "cx-9"],
        "ford": ["focus", "fiesta", "mondeo", "kuga", "explorer", "ecosport"],
        "chevrolet": ["cruze", "aveo", "captiva", "lacetti", "tahoe", "suburban"],
        "skoda": ["octavia", "rapid", "fabia", "superb", "kodiaq", "karoq"],
        "renault": ["logan", "sandero", "duster", "kaptur", "megane", "fluence"],
        "mitsubishi": ["lancer", "outlander", "asx", "pajero", "eclipse-cross", "l200"],
        "honda": ["civic", "accord", "cr-v", "pilot", "fit", "hr-v"],
        "bmw": ["3-series", "5-series", "x3", "x5", "x1", "1-series"],
        "mercedes-benz": ["c-class", "e-class", "s-class", "glc", "gle", "gla"],
        "audi": ["a3", "a4", "a6", "q3", "q5", "q7"],
        "lada": ["granta", "kalina", "priora", "vesta", "xray", "largus"],
    }


# ==================== –ú–û–î–ï–õ–ò –î–ê–ù–ù–´–• ====================

from parsers import ReviewData


# ==================== –ü–ê–†–°–ï–†–´ ====================


from parsers import DromParser, Drive2Parser


# ==================== –ì–õ–ê–í–ù–´–ô –ü–ê–†–°–ï–† ====================


class AutoReviewsParser:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –ø–∞—Ä—Å–µ—Ä–∞ –æ—Ç–∑—ã–≤–æ–≤ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π"""

    def __init__(self, db_path: str = Config.DB_PATH):
        self.db = Database(db_path)
        self.review_repo = ReviewRepository(self.db)
        self.queue_repo = QueueRepository(self.db)
        self.setup_logging()
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–æ–≤
        self.drom_parser = DromParser(self.review_repo)
        self.drive2_parser = Drive2Parser(self.review_repo)

    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)

        log_file = log_dir / f"parser_{datetime.now().strftime('%Y%m%d')}.log"

        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(log_file, encoding="utf-8"),
                logging.StreamHandler(),
            ],
        )

    def initialize_sources_queue(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—á–µ—Ä–µ–¥–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        self.queue_repo.initialize(Config.TARGET_BRANDS)
        total_sources = (
            len(Config.TARGET_BRANDS)
            * sum(len(models) for models in Config.TARGET_BRANDS.values())
            * 2
        )
        print(f"‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –æ—á–µ—Ä–µ–¥—å –∏–∑ {total_sources} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

    def get_next_source(self) -> Optional[Tuple[str, str, str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        return self.queue_repo.get_next()

    def mark_source_completed(
        self, brand: str, model: str, source: str, pages_parsed: int, reviews_found: int
    ):
        """–û—Ç–º–µ—Ç–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–≥–æ"""
        self.queue_repo.mark_completed(
            brand, model, source, pages_parsed, reviews_found
        )

    def parse_single_source(self, brand: str, model: str, source: str) -> int:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        print(f"\nüéØ –ü–∞—Ä—Å–∏–Ω–≥: {brand} {model} –Ω–∞ {source}")

        reviews = []
        data = {"brand": brand, "model": model, "max_pages": Config.PAGES_PER_SESSION}

        try:
            if source == "drom.ru":
                # –í—ã–∑—ã–≤–∞–µ–º –º–µ—Ç–æ–¥ —Å –ø–µ—Ä–µ–¥–∞—á–µ–π —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –ø–∞—Ä—Å–µ—Ä–∞ —á–µ—Ä–µ–∑ metadata
                reviews = self.drom_parser.parse_brand_model_reviews(
                    data, metadata=self.drom_parser
                )
            elif source == "drive2.ru":
                # –í—ã–∑—ã–≤–∞–µ–º –º–µ—Ç–æ–¥ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–≥–Ω–∞—Ç—É—Ä–æ–π
                reviews = self.drive2_parser.parse_brand_model_reviews(data)
            if reviews is None:
                logging.warning(
                    f"Parser returned no reviews for {brand} {model} on {source}"
                )
                reviews = []

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–∑—ã–≤—ã –≤ –±–∞–∑—É
            saved_count = 0
            for review in reviews:
                if self.review_repo.save(review):
                    saved_count += 1

            print(f"  üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –∏–∑ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤")

            # –û—Ç–º–µ—á–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π
            self.mark_source_completed(
                brand, model, source, Config.PAGES_PER_SESSION, saved_count
            )

            return saved_count

        except Exception as e:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {brand} {model} {source}: {e}")
            return 0

    def run_parsing_session(
        self, max_sources: int = 10, session_duration_hours: int = 2
    ):
        """–ó–∞–ø—É—Å–∫ —Å–µ—Å—Å–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        print(f"\nüöÄ –ó–ê–ü–£–°–ö –°–ï–°–°–ò–ò –ü–ê–†–°–ò–ù–ì–ê")
        print(f"{'='*60}")
        print(f"–ú–∞–∫—Å–∏–º—É–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∑–∞ —Å–µ—Å—Å–∏—é: {max_sources}")
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {session_duration_hours} —á–∞—Å–æ–≤")
        print(f"{'='*60}")

        session_start = datetime.now()
        session_end = session_start + timedelta(hours=session_duration_hours)

        sources_processed = 0
        total_reviews_saved = 0

        while sources_processed < max_sources and datetime.now() < session_end:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫
            source_info = self.get_next_source()

            if not source_info:
                print("\n‚úÖ –í—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
                break

            brand, model, source = source_info

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
            current_count = self.review_repo.get_reviews_count(brand, model)
            if current_count >= Config.MAX_REVIEWS_PER_MODEL:
                print(
                    f"  ‚ö†Ô∏è –õ–∏–º–∏—Ç –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è {brand} {model} –¥–æ—Å—Ç–∏–≥–Ω—É—Ç ({current_count})"
                )
                self.mark_source_completed(brand, model, source, 0, 0)
                continue

            # –ü–∞—Ä—Å–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫
            try:
                reviews_saved = self.parse_single_source(brand, model, source)
                total_reviews_saved += reviews_saved
                sources_processed += 1

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
                if sources_processed < max_sources:
                    delay = random.uniform(30, 60)  # 30-60 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
                    print(f"  ‚è≥ –ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫...")
                    time.sleep(delay)

            except Exception as e:
                logging.error(
                    f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {brand} {model} {source}: {e}"
                )
                sources_processed += 1

                # –£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –ø–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                time.sleep(Config.ERROR_DELAY)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏
        session_duration = datetime.now() - session_start

        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ï–°–°–ò–ò")
        print(f"{'='*60}")
        print(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {session_duration}")
        print(f"–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {sources_processed}")
        print(f"–û—Ç–∑—ã–≤–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {total_reviews_saved}")
        print(f"{'='*60}")

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã
        stats = self.review_repo.get_parsing_stats()
        print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•")
        print(f"{'='*60}")
        print(f"–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {stats['total_reviews']}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤: {stats['unique_brands']}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {stats['unique_models']}")
        print(f"–ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º: {stats['by_source']}")
        print(f"–ü–æ —Ç–∏–ø–∞–º: {stats['by_type']}")
        print(f"{'='*60}")

    def run_continuous_parsing(
        self, daily_sessions: int = 4, session_sources: int = 10
    ):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏"""
        print(f"\nüîÑ –†–ï–ñ–ò–ú –ù–ï–ü–†–ï–†–´–í–ù–û–ì–û –ü–ê–†–°–ò–ù–ì–ê")
        print(f"–°–µ—Å—Å–∏–π –≤ –¥–µ–Ω—å: {daily_sessions}")
        print(f"–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∑–∞ —Å–µ—Å—Å–∏—é: {session_sources}")
        print(f"–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏: {24 // daily_sessions} —á–∞—Å–æ–≤")

        session_interval = timedelta(hours=24 // daily_sessions)

        while True:
            try:
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Å—Å–∏—é –ø–∞—Ä—Å–∏–Ω–≥–∞
                self.run_parsing_session(
                    max_sources=session_sources, session_duration_hours=2
                )

                # –ñ–¥–µ–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–π —Å–µ—Å—Å–∏–∏
                next_session = datetime.now() + session_interval
                print(
                    f"\n‚è∞ –°–ª–µ–¥—É—é—â–∞—è —Å–µ—Å—Å–∏—è: {next_session.strftime('%Y-%m-%d %H:%M:%S')}"
                )

                while datetime.now() < next_session:
                    remaining = next_session - datetime.now()
                    print(f"‚è≥ –î–æ —Å–ª–µ–¥—É—é—â–µ–π —Å–µ—Å—Å–∏–∏: {remaining}", end="\r")
                    time.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É

            except KeyboardInterrupt:
                print("\nüëã –ü–∞—Ä—Å–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                break
            except Exception as e:
                logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–º –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
                print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
                print("‚è≥ –ü–∞—É–∑–∞ 30 –º–∏–Ω—É—Ç –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                time.sleep(1800)  # 30 –º–∏–Ω—É—Ç –ø–∞—É–∑–∞ –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–µ


# ==================== –£–¢–ò–õ–ò–¢–´ –£–ü–†–ê–í–õ–ï–ù–ò–Ø ====================


class ParserManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–æ–º"""

    def __init__(self, db_path: str = Config.DB_PATH):
        self.parser = AutoReviewsParser(db_path)

    def show_status(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –æ—á–µ—Ä–µ–¥–∏"""
        stats = self.parser.review_repo.get_parsing_stats()

        print(f"\nüìä –°–¢–ê–¢–£–° –ë–ê–ó–´ –î–ê–ù–ù–´–•")
        print(f"{'='*50}")
        print(f"–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {stats['total_reviews']:,}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤: {stats['unique_brands']}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {stats['unique_models']}")

        if stats["by_source"]:
            print(f"\n–ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
            for source, count in stats["by_source"].items():
                print(f"  {source}: {count:,}")

        if stats["by_type"]:
            print(f"\n–ü–æ —Ç–∏–ø–∞–º:")
            for type_name, count in stats["by_type"].items():
                print(f"  {type_name}: {count:,}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–µ—Ä–µ–¥–∏
        queue_stats = self.parser.queue_repo.get_stats()

        print(f"\nüìã –°–¢–ê–¢–£–° –û–ß–ï–†–ï–î–ò")
        print(f"{'='*50}")
        total_sources = sum(queue_stats.values())

        for status, count in queue_stats.items():
            percentage = (count / total_sources * 100) if total_sources > 0 else 0
            print(f"{status}: {count} ({percentage:.1f}%)")

        print(f"–í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {total_sources}")

    def reset_queue(self):
        """–°–±—Ä–æ—Å –æ—á–µ—Ä–µ–¥–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        print("üîÑ –°–±—Ä–æ—Å –æ—á–µ—Ä–µ–¥–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        self.parser.initialize_sources_queue()

    def export_data(self, output_format: str = "xlsx"):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã"""
        print(f"üì§ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ {output_format}...")

        query = """
            SELECT
                source, type, brand, model, year, title, author, rating,
                content, pros, cons, mileage, engine_volume, fuel_type,
                transmission, body_type, drive_type, publish_date,
                views_count, likes_count, comments_count, url, parsed_at
            FROM reviews
            ORDER BY brand, model, parsed_at DESC
        """

        df_data = []
        with self.parser.db.connection() as conn:
            cursor = conn.cursor()
            cursor.execute(query)
            columns = [description[0] for description in cursor.description]
            for row in cursor.fetchall():
                df_data.append(dict(zip(columns, row)))

        if not df_data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if output_format.lower() == "xlsx":
            filename = f"auto_reviews_export_{timestamp}.xlsx"
            bt.write_excel(df_data, filename.replace(".xlsx", ""))
            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {filename}")

        elif output_format.lower() == "json":
            filename = f"auto_reviews_export_{timestamp}.json"
            bt.write_json(df_data, filename.replace(".json", ""))
            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {filename}")

        else:
            print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {output_format}")


# ==================== –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ====================


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞"""
    import argparse

    parser = argparse.ArgumentParser(description="–ü–∞—Ä—Å–µ—Ä –æ—Ç–∑—ã–≤–æ–≤ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π")
    parser.add_argument(
        "command",
        choices=["init", "parse", "continuous", "status", "export"],
        help="–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
    )
    parser.add_argument(
        "--sources",
        type=int,
        default=10,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∑–∞ —Å–µ—Å—Å–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 10)",
    )
    parser.add_argument(
        "--sessions",
        type=int,
        default=4,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Å—Å–∏–π –≤ –¥–µ–Ω—å –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 4)",
    )
    parser.add_argument(
        "--format",
        default="xlsx",
        choices=["xlsx", "json"],
        help="–§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: xlsx)",
    )

    args = parser.parse_args()

    manager = ParserManager()

    if args.command == "init":
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞...")
        manager.reset_queue()
        print("‚úÖ –ü–∞—Ä—Å–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")

    elif args.command == "parse":
        print("üéØ –ó–∞–ø—É—Å–∫ —Ä–∞–∑–æ–≤–æ–π —Å–µ—Å—Å–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        manager.parser.run_parsing_session(max_sources=args.sources)

    elif args.command == "continuous":
        print("üîÑ –ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        manager.parser.run_continuous_parsing(
            daily_sessions=args.sessions, session_sources=args.sources
        )

    elif args.command == "status":
        manager.show_status()

    elif args.command == "export":
        manager.export_data(output_format=args.format)


if __name__ == "__main__":
    main()

    # parser = AutoReviewsParser()
    # parser.run_parsing_session(max_sources=10)
    # parser.run_continuous_parsing(daily_sessions=4, session_sources=10)
    # parser.run_parsing_session(max_sources=10)
